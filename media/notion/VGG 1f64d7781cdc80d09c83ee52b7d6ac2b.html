<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>VGG</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.collection-content td {
	white-space: pre-wrap;
	word-break: break-word;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

blockquote.quote-large {
	font-size: 1.25em;
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray {
	color: rgba(142, 139, 134, 1);
	fill: rgba(142, 139, 134, 1);
}
.highlight-brown {
	color: rgba(182, 137, 101, 1);
	fill: rgba(182, 137, 101, 1);
}
.highlight-orange {
	color: rgba(213, 128, 59, 1);
	fill: rgba(213, 128, 59, 1);
}
.highlight-yellow {
	color: rgba(229, 178, 68, 1);
	fill: rgba(229, 178, 68, 1);
}
.highlight-teal {
	color: rgba(85, 167, 124, 1);
	fill: rgba(85, 167, 124, 1);
}
.highlight-blue {
	color: rgba(35, 131, 226, 1);
	fill: rgba(35, 131, 226, 1);
}
.highlight-purple {
	color: rgba(181, 119, 214, 1);
	fill: rgba(181, 119, 214, 1);
}
.highlight-pink {
	color: rgba(219, 105, 153, 1);
	fill: rgba(219, 105, 153, 1);
}
.highlight-red {
	color: rgba(229, 100, 88, 1);
	fill: rgba(229, 100, 88, 1);
}
.highlight-default_background {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray_background {
	background: rgba(240, 239, 237, 1);
}
.highlight-brown_background {
	background: rgba(245, 237, 233, 1);
}
.highlight-orange_background {
	background: rgba(251, 235, 222, 1);
}
.highlight-yellow_background {
	background: rgba(249, 243, 220, 1);
}
.highlight-teal_background {
	background: rgba(232, 241, 236, 1);
}
.highlight-blue_background {
	background: rgba(232, 242, 250, 1);
}
.highlight-purple_background {
	background: rgba(243, 235, 249, 1);
}
.highlight-pink_background {
	background: rgba(250, 233, 241, 1);
}
.highlight-red_background {
	background: rgba(252, 233, 231, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(142, 139, 134, 1);
	fill: rgba(142, 139, 134, 1);
}
.block-color-brown {
	color: rgba(182, 137, 101, 1);
	fill: rgba(182, 137, 101, 1);
}
.block-color-orange {
	color: rgba(213, 128, 59, 1);
	fill: rgba(213, 128, 59, 1);
}
.block-color-yellow {
	color: rgba(229, 178, 68, 1);
	fill: rgba(229, 178, 68, 1);
}
.block-color-teal {
	color: rgba(85, 167, 124, 1);
	fill: rgba(85, 167, 124, 1);
}
.block-color-blue {
	color: rgba(35, 131, 226, 1);
	fill: rgba(35, 131, 226, 1);
}
.block-color-purple {
	color: rgba(181, 119, 214, 1);
	fill: rgba(181, 119, 214, 1);
}
.block-color-pink {
	color: rgba(219, 105, 153, 1);
	fill: rgba(219, 105, 153, 1);
}
.block-color-red {
	color: rgba(229, 100, 88, 1);
	fill: rgba(229, 100, 88, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(240, 239, 237, 1);
}
.block-color-brown_background {
	background: rgba(245, 237, 233, 1);
}
.block-color-orange_background {
	background: rgba(251, 235, 222, 1);
}
.block-color-yellow_background {
	background: rgba(249, 243, 220, 1);
}
.block-color-teal_background {
	background: rgba(232, 241, 236, 1);
}
.block-color-blue_background {
	background: rgba(232, 242, 250, 1);
}
.block-color-purple_background {
	background: rgba(243, 235, 249, 1);
}
.block-color-pink_background {
	background: rgba(250, 233, 241, 1);
}
.block-color-red_background {
	background: rgba(252, 233, 231, 1);
}
.select-value-color-default { background-color: rgba(42, 28, 0, 0.07); }
.select-value-color-gray { background-color: rgba(28, 19, 1, 0.11); }
.select-value-color-brown { background-color: rgba(127, 51, 0, 0.156); }
.select-value-color-orange { background-color: rgba(196, 88, 0, 0.203); }
.select-value-color-yellow { background-color: rgba(209, 156, 0, 0.282); }
.select-value-color-green { background-color: rgba(0, 96, 38, 0.156); }
.select-value-color-blue { background-color: rgba(0, 99, 174, 0.172); }
.select-value-color-purple { background-color: rgba(92, 0, 163, 0.141); }
.select-value-color-pink { background-color: rgba(183, 0, 78, 0.152); }
.select-value-color-red { background-color: rgba(206, 24, 0, 0.164); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="1f64d778-1cdc-80d0-9c83-ee52b7d6ac2b" class="page sans"><header><h1 class="page-title">VGG</h1><p class="page-description"></p></header><div class="page-body"><hr id="1f64d778-1cdc-80fe-879b-c1e0856d2b55"/><p id="1f64d778-1cdc-800f-a5fd-e6c13d469582" class="">
</p><h2 id="1f64d778-1cdc-8066-8d01-ca7e1b23f74f" class="">기존의 문제점</h2><hr id="1f64d778-1cdc-8058-9463-d1bd6a11e0ed"/><ol type="1" id="1f64d778-1cdc-80ab-8559-c40ddd66a51a" class="numbered-list" start="1"><li>아키텍처 설계의 복잡성<ul id="1f64d778-1cdc-808c-85a8-fb1d340ddc1c" class="bulleted-list"><li style="list-style-type:disc">AlexNet(2012)<ul id="1f64d778-1cdc-803c-a6d0-eb52071e8a9e" class="bulleted-list"><li style="list-style-type:circle">11<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">×</span></span></span></span></span><span>﻿</span></span>11, 5<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">×</span></span></span></span></span><span>﻿</span></span>5 그리고 3<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">×</span></span></span></span></span><span>﻿</span></span>3 등 서로 다른 크기의 필터를 섞어 사용</li></ul><ul id="1f64d778-1cdc-8048-827d-c3a98143a841" class="bulleted-list"><li style="list-style-type:circle">레이어별 채널 수와 크기가 불균일하여 구조 파악과 구현이 다소 번거로움</li></ul></li></ul></li></ol><ol type="1" id="1f64d778-1cdc-80aa-867d-ed8a5d70b87e" class="numbered-list" start="2"><li>깊이에 따른 최적화 어려움<ul id="1f64d778-1cdc-808c-9a2b-d67a0ed26892" class="bulleted-list"><li style="list-style-type:disc">네트워크가 깊어질수록 학습이 어려워지고, 파라미터, 계산량이 폭발적으로 증가한다.</li></ul><ul id="1f64d778-1cdc-806b-899d-fe24f8711023" class="bulleted-list"><li style="list-style-type:disc">비균일 구조에서는 어느 부분을 깊게 쌓아야 할지, 어떤 크기의 필터를 써야 할지 설계 가이드라인 부재</li></ul></li></ol><ol type="1" id="1f64d778-1cdc-8018-af94-c3aa8bd6e3d7" class="numbered-list" start="3"><li>표현력 VS 구현 용이성의 트레이드오프<ul id="1f64d778-1cdc-80b8-8b05-cf676fbc77c0" class="bulleted-list"><li style="list-style-type:disc">깊게 쌓자! 라는 마음은 명확했으나, 메모리와 연산이 부담</li></ul></li></ol><p id="1f64d778-1cdc-80d9-9ddf-cae5b2eb4f74" class="">
</p><p id="1f64d778-1cdc-80f0-a51c-c88788c1df60" class="">
</p><h2 id="1f64d778-1cdc-809d-8721-da3b131c51ab" class="">VGGNet</h2><p id="1f64d778-1cdc-809a-b0ec-c1d9542fa2fd" class=""> Simonyan &amp; Zisserman(2014)이 제안한 매우 **균일(uniform)**하고 <strong>단순한</strong> 구조 덕분에, “깊은 네트워크 설계의 가이드라인” 역할이 되었다.<br/></p><hr id="1f64d778-1cdc-80ee-9027-d4f840d830c7"/><ol type="1" id="1f64d778-1cdc-8015-b54c-decf4b2ef236" class="numbered-list" start="1"><li>3<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">×</span></span></span></span></span><span>﻿</span></span>3 필터의 반복 사용<ul id="49706573-f909-4ef2-a498-873c97fcf440" class="bulleted-list"><li style="list-style-type:disc"><strong>동기</strong>:<ul id="84ca62fc-da25-48c8-8769-dd138cce5141" class="bulleted-list"><li style="list-style-type:circle">작은 필터 여러 개를 연속으로 쌓으면,<ol type="1" id="583824d8-5eda-41ed-9c22-8db0649ed69a" class="numbered-list" start="1"><li><strong>수용 영역(Receptive field)</strong>: 예를 들어 3×3 × 3겹 → 사실상 7×7 효과</li></ol><ol type="1" id="7abad132-ff5e-475f-98ec-ce699115e8a3" class="numbered-list" start="2"><li><strong>비선형성 증가</strong>: 각 층마다 ReLU를 삽입 → 복잡한 표현 학습</li></ol></li></ul></li></ul><ul id="79416e15-addb-4396-835c-e8ea964e44f7" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>:<ul id="a1ee45cb-ff36-42d5-9cf9-98b4f67a68d4" class="bulleted-list"><li style="list-style-type:circle">파라미터 효율성: 하나의 7×7 필터(49개 매개변수) 대신, 3×3×3개(27개 매개변수)</li></ul><ul id="3b329baf-356c-4c85-ba90-d378926babb3" class="bulleted-list"><li style="list-style-type:circle">깊게 쌓아도 설계 패턴이 단순(“3×3 conv → ReLU → 3×3 conv → ReLU → … → Pool”)</li></ul></li></ul></li></ol><ol type="1" id="1f64d778-1cdc-80ad-b7d2-e79d698d9a8b" class="numbered-list" start="2"><li>네트워크 깊이의 확장<ul id="f6efd9ea-cffa-437d-a302-f0cac98f4ff6" class="bulleted-list"><li style="list-style-type:disc">VGG16: 합성곱 13개 + 완전연결 3개 = 총 16개 학습층</li></ul><ul id="fcd817bc-1583-4b3a-9f6d-79d750d65a25" class="bulleted-list"><li style="list-style-type:disc">VGG19: 합성곱 16개 + 완전연결 3개 = 총 19개 학습층</li></ul></li></ol><ol type="1" id="1f64d778-1cdc-80fc-8799-daa3d19d9f68" class="numbered-list" start="3"><li>균일한 설계<ul id="24f84bd5-a95e-452d-8a53-ac1652b0f597" class="bulleted-list"><li style="list-style-type:disc"><strong>“블록(block)” 단위 반복</strong>:<ul id="713f4db6-7038-461b-affb-aa8b49426a53" class="bulleted-list"><li style="list-style-type:circle">채널 수만 블록마다 2배씩 증가(64 → 128 → 256 → 512 → 512)</li></ul><ul id="315c8a09-aae9-43cd-8146-bb5a70f0efed" class="bulleted-list"><li style="list-style-type:circle">각 블록 내에서 동일한 개수의 3×3 conv가 반복</li></ul></li></ul><ul id="2c671f22-fea8-4809-8dbf-bdc0fb54d08c" class="bulleted-list"><li style="list-style-type:disc"><strong>풀링 전략</strong>:<ul id="5ede00dd-8f29-4b3a-a1a3-57ec6cfc1481" class="bulleted-list"><li style="list-style-type:circle">*MaxPool(2×2, stride=2)**로 블록별 다운샘플링</li></ul><ul id="8d4777f6-b69f-44db-9d2c-dd88458b4af4" class="bulleted-list"><li style="list-style-type:circle">위치 불변성(invariance)과 계산량 절감</li></ul></li></ul><p id="1f64d778-1cdc-80cb-837e-ed3e491b19c6" class="">
</p></li></ol><ol type="1" id="1f64d778-1cdc-8093-8118-fdd24e701808" class="numbered-list" start="4"><li>기타 세부 기법<ul id="fe8031ab-b104-4f79-b350-97065c922885" class="bulleted-list"><li style="list-style-type:disc"><strong>ReLU 활성화</strong>: 비포화 함수로 학습 안정화 및 속도 개선</li></ul><ul id="85f8c250-977a-4d45-b140-5b3df0859129" class="bulleted-list"><li style="list-style-type:disc"><strong>Dropout</strong> (완전연결 층): 과적합 방지</li></ul><ul id="eca83d0a-88eb-468a-b088-623c65041d12" class="bulleted-list"><li style="list-style-type:disc"><strong>초기화</strong>: 작은 Gaussian 분포로 가중치 초기화 → 학습 안정성 확보</li></ul><ul id="5bbeb780-f1b5-4e72-851a-bfa56dd98399" class="bulleted-list"><li style="list-style-type:disc"><strong>전이 학습(Transfer Learning)</strong> 친화성:<ul id="f5d339b7-8763-43f3-9d01-4f40008f7089" class="bulleted-list"><li style="list-style-type:circle">단순한 구조 덕분에, ImageNet 사전학습 모델을 다양한 과제에 손쉽게 적용 가능</li></ul></li></ul></li></ol><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1f64d778-1cdc-8071-a949-daaa57e48482" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">import torch
import torch.nn as nn

class VGG16(nn.Module):
    def __init__(self, num_classes=1000):
        super(VGG16, self).__init__()
        # feature extractor: Convolutional blocks
        self.features = nn.Sequential(
            # Block 1
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            # Block 2
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            # Block 3
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            # Block 4
            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            # Block 5
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        # classifier: Fully connected layers
        self.classifier = nn.Sequential(
            nn.Linear(512 * 7 * 7, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)  # flatten
        x = self.classifier(x)
        return x

if __name__ == &quot;__main__&quot;:
    # 모델 생성 및 구조 출력
    model = VGG16(num_classes=1000)
    print(model)
    # 임의 입력으로 테스트
    input_tensor = torch.randn(1, 3, 224, 224)
    output = model(input_tensor)
    print(output.shape)  # torch.Size([1, 1000])
</code></pre><p id="1f64d778-1cdc-801d-b0db-d86fb0cdd0d0" class="">
</p><p id="1f64d778-1cdc-80eb-b98d-e2d870b8dfcb" class="">전이학습의 예시</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1f64d778-1cdc-8068-8ed3-ce7a612aa68d" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">import os
import time
import copy
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models

# 1. 데이터 전처리 및 로더 설정
data_dir = &#x27;data/hymenoptera_data&#x27;
batch_size = 32
num_workers = 4

data_transforms = {
    &#x27;train&#x27;: transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
    &#x27;val&#x27;: transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
}

datasets_dict = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])
                 for x in [&#x27;train&#x27;, &#x27;val&#x27;]}
dataloaders = {x: torch.utils.data.DataLoader(datasets_dict[x], batch_size=batch_size,
                                              shuffle=True, num_workers=num_workers)
               for x in [&#x27;train&#x27;, &#x27;val&#x27;]}
dataset_sizes = {x: len(datasets_dict[x]) for x in [&#x27;train&#x27;, &#x27;val&#x27;]}
class_names = datasets_dict[&#x27;train&#x27;].classes

device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)

# 2. 사전 학습된 VGG16 모델 불러오고 특성 추출기 동결
model = models.vgg16(pretrained=True)
for param in model.features.parameters():
    param.requires_grad = False

# 3. 분류기 교체
num_ftrs = model.classifier[6].in_features
model.classifier[6] = nn.Linear(num_ftrs, len(class_names))
model = model.to(device)

# 4. 손실 함수, 최적화기, 스케줄러 정의
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, momentum=0.9)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)

# 5. 훈련 함수

def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    since = time.time()
    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):
        print(f&#x27;Epoch {epoch+1}/{num_epochs}&#x27;)
        print(&#x27;-&#x27; * 10)

        # 각 epoch마다 학습(train)과 검증(val) 수행
        for phase in [&#x27;train&#x27;, &#x27;val&#x27;]:
            if phase == &#x27;train&#x27;:
                model.train()
            else:
                model.eval()

            running_loss = 0.0
            running_corrects = 0

            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                optimizer.zero_grad()

                with torch.set_grad_enabled(phase == &#x27;train&#x27;):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    if phase == &#x27;train&#x27;:
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            if phase == &#x27;train&#x27;:
                scheduler.step()

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            print(f&#x27;{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}&#x27;)

            # 최선 모델 저장
            if phase == &#x27;val&#x27; and epoch_acc &gt; best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())

        print()

    time_elapsed = time.time() - since
    print(f&#x27;Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s&#x27;)
    print(f&#x27;Best val Acc: {best_acc:.4f}&#x27;)

    # 최선 모델 가중치 로딩
    model.load_state_dict(best_model_wts)
    return model

# 6. 모델 훈련 실행
if __name__ == &#x27;__main__&#x27;:
    trained_model = train_model(model, criterion, optimizer, scheduler, num_epochs=10)
    torch.save(trained_model.state_dict(), &#x27;vgg16_finetuned.pth&#x27;)
</code></pre><p id="1f64d778-1cdc-80cb-9799-f35471401bdf" class="">
</p><h2 id="1f64d778-1cdc-808b-b76e-c34fc73fec76" class="">한  줄 요약</h2><hr id="1f64d778-1cdc-80bd-b817-dee8b3dc684b"/><p id="1f64d778-1cdc-8052-b902-c1700ea2ab47" class=""><em>“VGG는 ‘3×3 필터 반복’과 ‘블록별 균일 구조’를 통해, 깊이를 간단하면서도 효과적으로 확장하는 설계 원칙을 제시한 모델이다.”</em></p><p id="1f64d778-1cdc-806a-a479-fd55734785e0" class="">
</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>