<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>허깅페이스</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.collection-content td {
	white-space: pre-wrap;
	word-break: break-word;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

blockquote.quote-large {
	font-size: 1.25em;
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray {
	color: rgba(142, 139, 134, 1);
	fill: rgba(142, 139, 134, 1);
}
.highlight-brown {
	color: rgba(182, 137, 101, 1);
	fill: rgba(182, 137, 101, 1);
}
.highlight-orange {
	color: rgba(213, 128, 59, 1);
	fill: rgba(213, 128, 59, 1);
}
.highlight-yellow {
	color: rgba(229, 178, 68, 1);
	fill: rgba(229, 178, 68, 1);
}
.highlight-teal {
	color: rgba(85, 167, 124, 1);
	fill: rgba(85, 167, 124, 1);
}
.highlight-blue {
	color: rgba(35, 131, 226, 1);
	fill: rgba(35, 131, 226, 1);
}
.highlight-purple {
	color: rgba(181, 119, 214, 1);
	fill: rgba(181, 119, 214, 1);
}
.highlight-pink {
	color: rgba(219, 105, 153, 1);
	fill: rgba(219, 105, 153, 1);
}
.highlight-red {
	color: rgba(229, 100, 88, 1);
	fill: rgba(229, 100, 88, 1);
}
.highlight-default_background {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray_background {
	background: rgba(240, 239, 237, 1);
}
.highlight-brown_background {
	background: rgba(245, 237, 233, 1);
}
.highlight-orange_background {
	background: rgba(251, 235, 222, 1);
}
.highlight-yellow_background {
	background: rgba(249, 243, 220, 1);
}
.highlight-teal_background {
	background: rgba(232, 241, 236, 1);
}
.highlight-blue_background {
	background: rgba(232, 242, 250, 1);
}
.highlight-purple_background {
	background: rgba(243, 235, 249, 1);
}
.highlight-pink_background {
	background: rgba(250, 233, 241, 1);
}
.highlight-red_background {
	background: rgba(252, 233, 231, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(142, 139, 134, 1);
	fill: rgba(142, 139, 134, 1);
}
.block-color-brown {
	color: rgba(182, 137, 101, 1);
	fill: rgba(182, 137, 101, 1);
}
.block-color-orange {
	color: rgba(213, 128, 59, 1);
	fill: rgba(213, 128, 59, 1);
}
.block-color-yellow {
	color: rgba(229, 178, 68, 1);
	fill: rgba(229, 178, 68, 1);
}
.block-color-teal {
	color: rgba(85, 167, 124, 1);
	fill: rgba(85, 167, 124, 1);
}
.block-color-blue {
	color: rgba(35, 131, 226, 1);
	fill: rgba(35, 131, 226, 1);
}
.block-color-purple {
	color: rgba(181, 119, 214, 1);
	fill: rgba(181, 119, 214, 1);
}
.block-color-pink {
	color: rgba(219, 105, 153, 1);
	fill: rgba(219, 105, 153, 1);
}
.block-color-red {
	color: rgba(229, 100, 88, 1);
	fill: rgba(229, 100, 88, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(240, 239, 237, 1);
}
.block-color-brown_background {
	background: rgba(245, 237, 233, 1);
}
.block-color-orange_background {
	background: rgba(251, 235, 222, 1);
}
.block-color-yellow_background {
	background: rgba(249, 243, 220, 1);
}
.block-color-teal_background {
	background: rgba(232, 241, 236, 1);
}
.block-color-blue_background {
	background: rgba(232, 242, 250, 1);
}
.block-color-purple_background {
	background: rgba(243, 235, 249, 1);
}
.block-color-pink_background {
	background: rgba(250, 233, 241, 1);
}
.block-color-red_background {
	background: rgba(252, 233, 231, 1);
}
.select-value-color-default { background-color: rgba(42, 28, 0, 0.07); }
.select-value-color-gray { background-color: rgba(28, 19, 1, 0.11); }
.select-value-color-brown { background-color: rgba(127, 51, 0, 0.156); }
.select-value-color-orange { background-color: rgba(196, 88, 0, 0.203); }
.select-value-color-yellow { background-color: rgba(209, 156, 0, 0.282); }
.select-value-color-green { background-color: rgba(0, 96, 38, 0.156); }
.select-value-color-blue { background-color: rgba(0, 99, 174, 0.172); }
.select-value-color-purple { background-color: rgba(92, 0, 163, 0.141); }
.select-value-color-pink { background-color: rgba(183, 0, 78, 0.152); }
.select-value-color-red { background-color: rgba(206, 24, 0, 0.164); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="1f64d778-1cdc-809c-9ea6-dfde6b605714" class="page sans"><header><h1 class="page-title">허깅페이스</h1><p class="page-description"></p></header><div class="page-body"><h3 id="1f64d778-1cdc-804d-88cc-c3219080652f" class=""><strong>Hugging Face란?</strong></h3><p id="1f64d778-1cdc-8054-be11-c2a2173e48bd" class=""><strong>Hugging Face</strong>는 딥러닝 모델의 저장, 공유, 및 사용을 위한 플랫폼이자 생태계입니다.</p><p id="1f64d778-1cdc-803e-9ed0-ea082c30e729" class="">이미 학습된 다양한 사전 학습 모델(pretrained model)을 제공하며, 특히 자연어 처리(NLP)와 컴퓨터 비전(CV) 작업에서 널리 활용됩니다.</p><ul id="1f64d778-1cdc-8075-92cc-ca3e8017da5d" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>:<ul id="1f64d778-1cdc-8082-9733-fff012509dea" class="bulleted-list"><li style="list-style-type:circle">다양한 <strong>사전 학습 모델</strong>을 쉽게 가져다 쓸 수 있음.</li></ul><ul id="1f64d778-1cdc-80df-9a74-e6a12e6b7a7f" class="bulleted-list"><li style="list-style-type:circle">모델 배포, 학습, 평가까지 모두 지원.</li></ul><ul id="1f64d778-1cdc-809d-88e1-da0c476089d0" class="bulleted-list"><li style="list-style-type:circle">모델 허브(Model Hub)를 통해 수천 개의 공개 모델 제공.</li></ul><ul id="1f64d778-1cdc-80d7-ac63-e2f69ca96808" class="bulleted-list"><li style="list-style-type:circle">PyTorch와 TensorFlow 모두 지원.</li></ul></li></ul><p id="1f64d778-1cdc-806b-82be-ec1dc38b5df3" class="">
</p><hr id="1f64d778-1cdc-80d2-82ed-cfc8549afad6"/><h3 id="1f64d778-1cdc-8095-a5a6-c975b20ba8df" class=""><strong>1. 설치 및 환경 설정</strong></h3><p id="1f64d778-1cdc-800c-9e06-c8f4d9ed423c" class="">먼저 Hugging Face 라이브러리와 필요한 패키지를 설치합니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1f64d778-1cdc-80a8-ab13-f5c5af26694c" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">pip install transformers</code></pre><p id="1f64d778-1cdc-80e9-9b1b-cc77e5cb81cf" class="">
</p><hr id="1f64d778-1cdc-8014-badc-d84413bbb266"/><p id="1f64d778-1cdc-8030-801f-de5e3602f016" class="">
</p><p id="1f64d778-1cdc-8084-a1f0-eb30854609ef" class="">Hugging Face의 <code>pipeline</code>과 <code><strong>Fine-Tuning</strong></code>은 사전 학습 모델을 활용하는 두 가지 대표적인 방법입니다. 이 둘은 각각 다른 용도와 목표를 가지고 있으며, 이를 잘 이해하면 Hugging Face를 활용해 효율적으로 모델을 개발할 수 있습니다.</p><p id="1f64d778-1cdc-8068-be7a-dd466116f549" class="">
</p><hr id="1f64d778-1cdc-80ce-9699-ce5f36d5f60e"/><h2 id="1f64d778-1cdc-8053-aef1-eda44c66f279" class=""><strong>1. </strong><code><strong>pipeline</strong></code><strong>: 사전 학습 모델을 바로 활용</strong></h2><h3 id="1f64d778-1cdc-808d-9fab-d1d533f7ddf2" class=""><code><strong>pipeline</strong></code><strong>이란?</strong></h3><p id="1f64d778-1cdc-80d6-9644-f76df178347a" class="">Hugging Face의 <code>pipeline</code>은 특정 작업(예: 텍스트 분류, 감성 분석, 이미지 분류 등)을 빠르게 수행할 수 있도록 설계된 고수준 API입니다.</p><p id="1f64d778-1cdc-8047-9abe-c472732bf461" class=""><strong>복잡한 코드 없이</strong> 사전 학습된 모델을 바로 가져와 사용할 수 있습니다.</p><h3 id="1f64d778-1cdc-80de-bf84-d90f2040cc6f" class=""><strong>지원되는 작업</strong></h3><p id="1f64d778-1cdc-8039-93f6-cddcafaf0c72" class=""><code>pipeline</code>은 아래와 같은 작업에 사용할 수 있습니다:</p><ol type="1" id="1f64d778-1cdc-8049-871e-e54eaebbcad4" class="numbered-list" start="1"><li><strong>NLP 작업</strong>:<ul id="1f64d778-1cdc-80d2-83d4-f770c5399722" class="bulleted-list"><li style="list-style-type:disc">텍스트 분류 (<code>sentiment-analysis</code>)</li></ul><ul id="1f64d778-1cdc-80dc-8f4c-eb658b254294" class="bulleted-list"><li style="list-style-type:disc">요약 (<code>summarization</code>)</li></ul><ul id="1f64d778-1cdc-806c-b1be-f6ec4fa04e65" class="bulleted-list"><li style="list-style-type:disc">번역 (<code>translation</code>)</li></ul><ul id="1f64d778-1cdc-80a4-8442-c7f00161b7f6" class="bulleted-list"><li style="list-style-type:disc">질의응답 (<code>question-answering</code>)</li></ul><ul id="1f64d778-1cdc-806a-a5f7-c7d9212933a9" class="bulleted-list"><li style="list-style-type:disc">텍스트 생성 (<code>text-generation</code>)</li></ul></li></ol><ol type="1" id="1f64d778-1cdc-80f1-af1e-d497058fa413" class="numbered-list" start="2"><li><strong>컴퓨터 비전 작업</strong>:<ul id="1f64d778-1cdc-8087-8fab-c9add52702ba" class="bulleted-list"><li style="list-style-type:disc">이미지 분류 (<code>image-classification</code>)</li></ul><ul id="1f64d778-1cdc-80a3-ab7b-dc637239b3a7" class="bulleted-list"><li style="list-style-type:disc">객체 탐지 (<code>object-detection</code>)</li></ul><ul id="1f64d778-1cdc-8065-a963-f4ef27e9decf" class="bulleted-list"><li style="list-style-type:disc">이미지 세그멘테이션 (<code>image-segmentation</code>)</li></ul></li></ol><ol type="1" id="1f64d778-1cdc-8005-934d-c8d9f829e02a" class="numbered-list" start="3"><li><strong>오디오 작업</strong>:<ul id="1f64d778-1cdc-80ac-a709-e5d730253eef" class="bulleted-list"><li style="list-style-type:disc">음성 인식 (<code>automatic-speech-recognition</code>)</li></ul><ul id="1f64d778-1cdc-80a7-ae04-fc0abe1d06ae" class="bulleted-list"><li style="list-style-type:disc">오디오 분류 (<code>audio-classification</code>)</li></ul></li></ol><p id="1f64d778-1cdc-80c0-a2e7-efaf84fb2773" class="">
</p><h3 id="1f64d778-1cdc-80c0-bea8-c1d5df22078b" class=""><code><strong>pipeline</strong></code><strong>의 장점</strong></h3><ul id="1f64d778-1cdc-801d-9532-c280e9f2abe2" class="bulleted-list"><li style="list-style-type:disc"><strong>빠르고 간편함</strong>: 복잡한 전처리 및 설정 없이 바로 사용 가능.</li></ul><ul id="1f64d778-1cdc-800f-86fe-ce0ecdfd0ce6" class="bulleted-list"><li style="list-style-type:disc"><strong>사전 학습 모델 사용</strong>: Hugging Face Hub에서 제공하는 다양한 모델 활용.</li></ul><ul id="1f64d778-1cdc-80aa-80fd-c5dd1d05e2a5" class="bulleted-list"><li style="list-style-type:disc"><strong>적용 범위가 넓음</strong>: NLP, CV, 오디오 작업 등 다양한 작업 지원.</li></ul><p id="1f64d778-1cdc-8005-ba45-f21ca9d03887" class="">
</p><h3 id="1f64d778-1cdc-8077-8ab8-f13c0acf8768" class="">Pipelline을 활용한 이미지 분류 예시</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1f64d778-1cdc-809f-ae33-c78dd14f04f0" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">from transformers import pipeline

# 이미지 분류 파이프라인 생성
image_classifier = pipeline(&quot;image-classification&quot;, model=&quot;google/vit-base-patch16-224&quot;)

# 이미지 분류 수행
result = image_classifier(&quot;path_to_image.jpg&quot;)
print(result)
</code></pre><p id="1f64d778-1cdc-805a-8b0c-dde2b952c53b" class="">
</p><hr id="1f64d778-1cdc-8066-a915-d499dce23b97"/><h2 id="1f64d778-1cdc-8048-99cb-c1e06a4dacd3" class=""><strong>2.  Fine-Tuning: 새로운 작업에 맞게 모델 조정</strong></h2><h3 id="1f64d778-1cdc-8049-be67-e47a67d10ebb" class=""><strong>Fine-Tuning이란?</strong></h3><p id="1f64d778-1cdc-80bd-aad4-db70e41a9a82" class="">사전 학습된 모델의 일부를 <strong>새로운 데이터셋</strong>에 맞게 재학습하여, <strong>특정 작업</strong>에 최적화하는 방법입니다.</p><p id="1f64d778-1cdc-8095-bb88-e99dcdc12f57" class="">Fine-Tuning은 주로 아래와 같은 상황에서 사용됩니다:</p><ol type="1" id="1f64d778-1cdc-8059-a618-fe811aa0af92" class="numbered-list" start="1"><li><strong>사전 학습 모델이 제공하는 작업과 새로운 작업이 유사한 경우.</strong></li></ol><ol type="1" id="1f64d778-1cdc-8079-a488-f137a8b8ac87" class="numbered-list" start="2"><li><strong>데이터가 제한적인 경우.</strong></li></ol><hr id="1f64d778-1cdc-8025-9f9f-d4164e5110ab"/><h3 id="1f64d778-1cdc-80f0-8786-ee6600457905" class=""><strong>2.1 Fine-Tuning의 과정</strong></h3><ol type="1" id="1f64d778-1cdc-8092-bcb2-e3107c6cbaf9" class="numbered-list" start="1"><li><strong>사전 학습 모델 로드</strong>:<ul id="1f64d778-1cdc-80d5-86f0-c8e6b48f086a" class="bulleted-list"><li style="list-style-type:disc">Hugging Face Hub에서 원하는 사전 학습 모델 가져오기.</li></ul></li></ol><ol type="1" id="1f64d778-1cdc-80f7-a40d-f53a279bf225" class="numbered-list" start="2"><li><strong>데이터셋 준비</strong>:<ul id="1f64d778-1cdc-80e6-b954-f58a4ed4fe86" class="bulleted-list"><li style="list-style-type:disc">Hugging Face <code>datasets</code> 라이브러리를 사용하거나 PyTorch/TensorFlow로 데이터 준비.</li></ul></li></ol><ol type="1" id="1f64d778-1cdc-8036-876b-fa838f207b0c" class="numbered-list" start="3"><li><strong>모델 수정</strong>:<ul id="1f64d778-1cdc-8054-b5cb-e64741290bdb" class="bulleted-list"><li style="list-style-type:disc">기존 분류 레이어를 새로운 작업에 맞게 변경.</li></ul></li></ol><ol type="1" id="1f64d778-1cdc-801f-bd02-eb9f2b282e62" class="numbered-list" start="4"><li><strong>학습 설정</strong>:<ul id="1f64d778-1cdc-80ff-b541-f6df7b5651a5" class="bulleted-list"><li style="list-style-type:disc">옵티마이저, 손실 함수, 학습률 조정 등 설정.</li></ul></li></ol><ol type="1" id="1f64d778-1cdc-80b7-a2c3-f90dc68b8f77" class="numbered-list" start="5"><li><strong>훈련 시작</strong>:<ul id="1f64d778-1cdc-8052-a6a8-e341a4750334" class="bulleted-list"><li style="list-style-type:disc">Hugging Face의 <code>Trainer</code>를 사용하거나 PyTorch/TensorFlow로 직접 훈련.</li></ul></li></ol><p id="1f64d778-1cdc-80a8-a73e-f9fd9411cae3" class="">
</p><h3 id="1f64d778-1cdc-80bd-b0e5-d75404ba20a3" class="">Fine-Tuning 을 활용한 이미지 분류 예시</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1f64d778-1cdc-8011-b386-c39306f98ac1" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">import torch
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.utils.data import DataLoader
from transformers import ViTForImageClassification
from torch.optim import AdamW
from torch.nn import CrossEntropyLoss

# 1. 데이터 전처리 및 로드
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ViT 모델 입력 크기
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
])

# CIFAR-10 데이터셋
train_dataset = datasets.CIFAR10(root=&#x27;./data&#x27;, train=True, download=True, transform=transform)
test_dataset = datasets.CIFAR10(root=&#x27;./data&#x27;, train=False, download=True, transform=transform)

# DataLoader 정의
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# CIFAR-10 클래스
classes = (&#x27;plane&#x27;, &#x27;car&#x27;, &#x27;bird&#x27;, &#x27;cat&#x27;, &#x27;deer&#x27;, &#x27;dog&#x27;, &#x27;frog&#x27;, &#x27;horse&#x27;, &#x27;ship&#x27;, &#x27;truck&#x27;)

# 2. 사전 학습 모델 로드 및 설정
model_name = &quot;google/vit-base-patch16-224-in21k&quot;
model = ViTForImageClassification.from_pretrained(model_name, num_labels=10)  # CIFAR-10 클래스 수 설정

# GPU 사용 설정
device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
model.to(device)

# 3. 옵티마이저 및 손실 함수 정의
optimizer = AdamW(model.parameters(), lr=5e-5)
criterion = CrossEntropyLoss()

# 4. 학습 루프
epochs = 5
for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        # 옵티마이저 초기화
        optimizer.zero_grad()

        # 순전파 및 역전파
        outputs = model(pixel_values=inputs).logits
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # 손실 및 정확도 계산
        running_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    print(f&quot;Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct/total:.2f}%&quot;)

# 5. 테스트 데이터 평가
model.eval()
correct = 0
total = 0

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(pixel_values=inputs).logits
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f&quot;Test Accuracy: {100 * correct/total:.2f}%&quot;)

# 6. 최적 모델 저장
torch.save(model.state_dict(), &quot;finetuned_vit_cifar10.pth&quot;)
print(&quot;Model saved as finetuned_vit_cifar10.pth&quot;)
</code></pre><p id="1f64d778-1cdc-8071-9ad6-c1ec9ae0c3df" class="">
</p><h3 id="1f64d778-1cdc-8035-85d5-f220220cd53a" class=""><strong>4. 결론</strong></h3><ol type="1" id="1f64d778-1cdc-803c-8a19-d3b5f67d4abe" class="numbered-list" start="1"><li><strong>빠르고 간단한 작업</strong>: Hugging Face의 <code>pipeline</code>을 사용해 사전 학습된 모델을 즉시 활용.</li></ol><ol type="1" id="1f64d778-1cdc-80e6-9184-e0034321e217" class="numbered-list" start="2"><li><strong>새로운 작업에 최적화</strong>: Hugging Face의 <code>Fine-Tuning</code> 도구를 사용해 모델을 학습.</li></ol><ol type="1" id="1f64d778-1cdc-8093-85c2-f2fbb6d84189" class="numbered-list" start="3"><li><strong>모두의 강력한 도구</strong>: <code>transformers</code>와 <code>datasets</code> 라이브러리를 조합해 Hugging Face의 모든 기능을 활용하세요.</li></ol></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>