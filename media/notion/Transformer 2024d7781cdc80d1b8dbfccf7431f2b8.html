<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Transformer</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.collection-content td {
	white-space: pre-wrap;
	word-break: break-word;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

blockquote.quote-large {
	font-size: 1.25em;
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray {
	color: rgba(142, 139, 134, 1);
	fill: rgba(142, 139, 134, 1);
}
.highlight-brown {
	color: rgba(182, 137, 101, 1);
	fill: rgba(182, 137, 101, 1);
}
.highlight-orange {
	color: rgba(213, 128, 59, 1);
	fill: rgba(213, 128, 59, 1);
}
.highlight-yellow {
	color: rgba(229, 178, 68, 1);
	fill: rgba(229, 178, 68, 1);
}
.highlight-teal {
	color: rgba(85, 167, 124, 1);
	fill: rgba(85, 167, 124, 1);
}
.highlight-blue {
	color: rgba(35, 131, 226, 1);
	fill: rgba(35, 131, 226, 1);
}
.highlight-purple {
	color: rgba(181, 119, 214, 1);
	fill: rgba(181, 119, 214, 1);
}
.highlight-pink {
	color: rgba(219, 105, 153, 1);
	fill: rgba(219, 105, 153, 1);
}
.highlight-red {
	color: rgba(229, 100, 88, 1);
	fill: rgba(229, 100, 88, 1);
}
.highlight-default_background {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray_background {
	background: rgba(240, 239, 237, 1);
}
.highlight-brown_background {
	background: rgba(245, 237, 233, 1);
}
.highlight-orange_background {
	background: rgba(251, 235, 222, 1);
}
.highlight-yellow_background {
	background: rgba(249, 243, 220, 1);
}
.highlight-teal_background {
	background: rgba(232, 241, 236, 1);
}
.highlight-blue_background {
	background: rgba(232, 242, 250, 1);
}
.highlight-purple_background {
	background: rgba(243, 235, 249, 1);
}
.highlight-pink_background {
	background: rgba(250, 233, 241, 1);
}
.highlight-red_background {
	background: rgba(252, 233, 231, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(142, 139, 134, 1);
	fill: rgba(142, 139, 134, 1);
}
.block-color-brown {
	color: rgba(182, 137, 101, 1);
	fill: rgba(182, 137, 101, 1);
}
.block-color-orange {
	color: rgba(213, 128, 59, 1);
	fill: rgba(213, 128, 59, 1);
}
.block-color-yellow {
	color: rgba(229, 178, 68, 1);
	fill: rgba(229, 178, 68, 1);
}
.block-color-teal {
	color: rgba(85, 167, 124, 1);
	fill: rgba(85, 167, 124, 1);
}
.block-color-blue {
	color: rgba(35, 131, 226, 1);
	fill: rgba(35, 131, 226, 1);
}
.block-color-purple {
	color: rgba(181, 119, 214, 1);
	fill: rgba(181, 119, 214, 1);
}
.block-color-pink {
	color: rgba(219, 105, 153, 1);
	fill: rgba(219, 105, 153, 1);
}
.block-color-red {
	color: rgba(229, 100, 88, 1);
	fill: rgba(229, 100, 88, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(240, 239, 237, 1);
}
.block-color-brown_background {
	background: rgba(245, 237, 233, 1);
}
.block-color-orange_background {
	background: rgba(251, 235, 222, 1);
}
.block-color-yellow_background {
	background: rgba(249, 243, 220, 1);
}
.block-color-teal_background {
	background: rgba(232, 241, 236, 1);
}
.block-color-blue_background {
	background: rgba(232, 242, 250, 1);
}
.block-color-purple_background {
	background: rgba(243, 235, 249, 1);
}
.block-color-pink_background {
	background: rgba(250, 233, 241, 1);
}
.block-color-red_background {
	background: rgba(252, 233, 231, 1);
}
.select-value-color-default { background-color: rgba(42, 28, 0, 0.07); }
.select-value-color-gray { background-color: rgba(28, 19, 1, 0.11); }
.select-value-color-brown { background-color: rgba(127, 51, 0, 0.156); }
.select-value-color-orange { background-color: rgba(196, 88, 0, 0.203); }
.select-value-color-yellow { background-color: rgba(209, 156, 0, 0.282); }
.select-value-color-green { background-color: rgba(0, 96, 38, 0.156); }
.select-value-color-blue { background-color: rgba(0, 99, 174, 0.172); }
.select-value-color-purple { background-color: rgba(92, 0, 163, 0.141); }
.select-value-color-pink { background-color: rgba(183, 0, 78, 0.152); }
.select-value-color-red { background-color: rgba(206, 24, 0, 0.164); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="2024d778-1cdc-80d1-b8db-fccf7431f2b8" class="page sans"><header><h1 class="page-title">Transformer</h1><p class="page-description"></p></header><div class="page-body"><p id="2024d778-1cdc-800a-b2d1-e04cd5c1e1cf" class="">2017년 구글 브레인(현 <a href="https://namu.wiki/w/%EA%B5%AC%EA%B8%80%20%EB%94%A5%EB%A7%88%EC%9D%B8%EB%93%9C">구글 딥마인드</a>) 연구진이 논문 <a href="https://namu.wiki/w/Attention%20Is%20All%20You%20Need">Attention Is All You Need</a>에서 발표한 <a href="https://namu.wiki/w/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D">인공신경망</a> 구조로, 기존의 <a href="https://namu.wiki/w/%EC%88%9C%ED%99%98%20%EC%8B%A0%EA%B2%BD%EB%A7%9D">순환 신경망</a>(RNN)과 <a href="https://namu.wiki/w/%ED%95%A9%EC%84%B1%EA%B3%B1%20%EC%8B%A0%EA%B2%BD%EB%A7%9D">합성곱 신경망</a>(CNN)의 한계를 극복하며 등장했다.<br/>RNN 은 순차적인 계산이 필요하였고 <strong>병렬 처리의 어려움</strong>이 있었다. 병렬 처리가 어렵다보니, <a href="https://namu.wiki/w/GPU">GPU</a>와 같은 병렬 연산 장치의 효율성을 충분히 활용하기 어려웠고 모델 학습 속도를 저하 시키는 요인이 되었다.<br/><br/><br/></p><p id="2024d778-1cdc-8040-b413-fdeae4597101" class="">
</p><h1 id="2024d778-1cdc-8015-9b8d-d377a36f16ad" class=""><strong>1. 구조</strong></h1><p id="2024d778-1cdc-8069-9cc7-de0091e0565f" class="">
</p><ul id="b2e21696-25f7-42b0-bd97-6bea0f85d969" class="bulleted-list"><li style="list-style-type:disc"><strong>전체 구조</strong>: Encoder-Decoder 구조로 구성</li></ul><ul id="a73cfbbc-d00d-4066-9c7c-593c1df78020" class="bulleted-list"><li style="list-style-type:disc"><strong>목적</strong>: 시퀀스-투-시퀀스(Sequence-to-Sequence) 태스크에 최적화</li></ul><ul id="4c7971b4-dc9f-49a9-983c-2ce9d2a32135" class="bulleted-list"><li style="list-style-type:disc"><strong>주요 응용</strong>: 기계 번역, 텍스트 요약 등 입력 시퀀스를 다른 형태의 출력 시퀀스로 변환하는 작업</li></ul><p id="2024d778-1cdc-8026-928e-e59056b17005" class="">
</p><p id="2024d778-1cdc-804a-b24c-dd14f19c7059" class="">
</p><figure id="2024d778-1cdc-80f5-93a5-de46ebb97842" class="image"><a href="image%2073.png"><img style="width:528px" src="image%2073.png"/></a></figure><p id="2024d778-1cdc-8049-8475-d58dafd83789" class="">
</p><ul id="2024d778-1cdc-8099-93db-efc32daf870e" class="bulleted-list"><li style="list-style-type:disc"><strong>어텐션 메커니즘</strong></li></ul><p id="2024d778-1cdc-8025-a9bd-d0dea7954952" class="">마지막으로 언급할 필요가 있는 것은 <strong>고정된 크기의 문맥 벡터</strong>가 가진 한계이다. 초기 인코더-디코더 구조에서는 인코더가 입력 시퀀스 전체의 정보를 고정된 크기를 가진 문맥 벡터 하나로 압축해 디코더에 전달하는 방식이 주로 사용되었는데 이 과정에서 필연적으로 정보 병목 현상과 손실이 발생할 가능성이 있었다. 이 것을 해결하기 위해 도입된 것이 바로 <strong>어텐션 메커니즘(attention mechanism)</strong>.<br/><br/>⇒ 이런 방식은 효과는 있었지만 근본적으로 <a href="https://namu.wiki/w/RNN">RNN</a> 기반 구조가 지닌 순차적 처리 방식의 한계는 여전히 남아 있었다.<br/><br/></p><ul id="2024d778-1cdc-80c1-91b3-e33544c1fc69" class="bulleted-list"><li style="list-style-type:disc"><strong>셀프-어텐션</strong>(Self-Attention) 메커니즘</li></ul><p id="2024d778-1cdc-8039-baf1-e6385ebce24e" class="">트랜스포머는 이런 문제들을 해결하기 위해 순환 구조를 완전히 배제하고 대신 후술할 <strong>셀프-어텐션</strong>(Self-Attention) 메커니즘을 핵심 요소로 사용하여 시퀀스 내의 모든 단어 쌍 간의 관계를 직접적으로 모델링하고 병렬 처리 효율을 극대화했다.<br/><br/></p><h3 id="7543aaa5-60c3-4d53-ae74-f8f7b2853fec" class=""><strong>[모델 크기 및 변형]</strong></h3><p id="2024d778-1cdc-80d4-9ddd-cda7a9457b24" class="">
</p><h3 id="f523329f-a153-48b2-b615-7facba7c4773" class="">Transformer</h3><ul id="aa9c2590-2272-4091-9f99-3a894736b8b2" class="bulleted-list"><li style="list-style-type:disc"><strong>원본 논문 모델</strong>:<ul id="46b34593-7737-43af-8b6d-47a1e5357365" class="bulleted-list"><li style="list-style-type:circle">6개의 인코더/디코더 레이어</li></ul><ul id="feb99ac1-085c-48f1-99a6-01d3a631bf25" class="bulleted-list"><li style="list-style-type:circle">8개의 어텐션 헤드</li></ul><ul id="5c570fb6-6d0b-430b-be14-03a4884ea428" class="bulleted-list"><li style="list-style-type:circle">512 차원의 임베딩</li></ul></li></ul><ul id="92f29c71-db57-47e9-a599-14f5debcc945" class="bulleted-list"><li style="list-style-type:disc"><strong>주요 변형</strong>:<ul id="2c531bfd-55a5-4f3d-94c2-5b7516579506" class="bulleted-list"><li style="list-style-type:circle"><strong>GPT(Generative Pre-trained Transformer)</strong>: 디코더만 사용한 모델</li></ul><ul id="39131801-4745-48ba-abc8-a86eca573c77" class="bulleted-list"><li style="list-style-type:circle"><strong>T5(Text-to-Text Transfer Transformer)</strong>: 모든 NLP 태스크를 텍스트-투-텍스트 형식으로 변환</li></ul></li></ul><p id="2024d778-1cdc-80f1-bd98-e5671d4a7620" class="">
</p><p id="2024d778-1cdc-80be-b8ab-ed6979b84a36" class="">
</p><p id="2024d778-1cdc-806b-b726-e3c2f6a5bc67" class="">
</p><p id="2024d778-1cdc-803b-b767-de2f6b33507d" class="">
</p><p id="2024d778-1cdc-80b5-bd67-fc5e8a4fcd86" class="">
</p><h3 id="b54ad718-b3c2-4c8a-ad3d-e897d09c126e" class="">BERT [BERT 와의 차이]</h3><ul id="a27932a1-4f37-4a25-a32f-850a74305c86" class="bulleted-list"><li style="list-style-type:disc"><strong>전체 구조</strong>: Transformer의 Encoder 부분만 사용</li></ul><ul id="5d3d1fc8-483f-4054-af3d-cf539eec6610" class="bulleted-list"><li style="list-style-type:disc"><strong>목적</strong>: 언어 이해(Language Understanding) 태스크에 최적화</li></ul><ul id="d20bbada-1abb-4fa5-9df2-fce26916022d" class="bulleted-list"><li style="list-style-type:disc"><strong>주요 응용</strong>: 텍스트 분류, 개체명 인식, 질의응답 등 텍스트 이해 기반 작업</li></ul><p id="2024d778-1cdc-8023-a39a-fbd35c5e0410" class="">
</p><figure id="2024d778-1cdc-8000-b0a7-d9dfeca1ae23" class="image"><a href="image%2074.png"><img style="width:364.9940490722656px" src="image%2074.png"/></a></figure><p id="2024d778-1cdc-80d4-a32a-e9ecda80289a" class="">
</p><p id="2024d778-1cdc-80e4-a8bc-d32564a05715" class="">
</p><p id="2024d778-1cdc-80f7-907d-f38235b2565b" class="">
</p><h2 id="1b270600-b3f6-4746-a94c-71f73576aaf3" class="">2. 학습 방식</h2><h3 id="76bf1560-d897-4b4c-8732-98bcb935290c" class="">Transformer</h3><ul id="aa853a03-84cb-4021-b426-1ed3f1d37e1b" class="bulleted-list"><li style="list-style-type:disc"><strong>학습 방법</strong>: 지도 학습(Supervised Learning)</li></ul><ul id="83c78897-c08f-4f02-b78b-2f8c846e1a46" class="bulleted-list"><li style="list-style-type:disc"><strong>훈련 과정</strong>: 특정 태스크(예: 번역)에 대해 직접 훈련</li></ul><ul id="f95e62c6-3bdb-4a1b-9458-025b62b1f2b9" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터</strong>: 대응되는 입력-출력 쌍(예: 영어-프랑스어 문장 쌍)</li></ul><ul id="29898f1b-6aa6-4c9d-bee5-20585e7ada79" class="bulleted-list"><li style="list-style-type:disc"><strong>목적 함수</strong>: 출력 시퀀스의 각 위치에서 다음 토큰 예측</li></ul><p id="2024d778-1cdc-8017-a4cc-edf83eee420c" class="">
</p><p id="2024d778-1cdc-8057-9c4c-e3b102a26e92" class="">
</p><p id="2024d778-1cdc-8066-a2b4-e1d951272ded" class="">
</p><h2 id="184cef87-40ec-41ad-936d-b76f523d18cb" class="">3. 입력 처리</h2><h3 id="c2f703bc-fb0d-4b68-af66-d6c5d06c4af0" class="">Transformer</h3><ul id="7086f67f-cdf7-4587-8481-35e5c55a8a66" class="bulleted-list"><li style="list-style-type:disc"><strong>입력 처리</strong>: 소스 시퀀스와 타겟 시퀀스를 각각 인코더와 디코더에 입력</li></ul><ul id="4c9fb674-a74e-47a0-818c-645795f0b1df" class="bulleted-list"><li style="list-style-type:disc"><strong>특수 토큰</strong>: 시작([SOS])과 종료([EOS]) 토큰 사용</li></ul><ul id="f8833830-e3b5-401d-a8d2-73ed6bd80d0c" class="bulleted-list"><li style="list-style-type:disc"><strong>포지셔널 인코딩</strong>: 사인과 코사인 함수 기반 위치 정보 추가</li></ul><p id="2024d778-1cdc-80ef-ad5c-c503a4853a2b" class="">
</p><p id="2024d778-1cdc-806c-8a66-ff4c136e5a97" class="">
</p><p id="2024d778-1cdc-80f7-a8a5-e7565d92359d" class="">
</p><h2 id="201c635a-771c-4b04-bd3d-af8b106c760d" class="">4. 양방향성</h2><h3 id="6fe39651-e9f4-4b26-b5f9-c68284459229" class="">Transformer</h3><ul id="0bf5ea07-6055-407f-bd3b-a35128b1e4d3" class="bulleted-list"><li style="list-style-type:disc"><strong>인코더</strong>: 양방향(Bidirectional) 컨텍스트 인코딩<ul id="0d36b3a1-b497-4694-a813-9e8e6d3ed07d" class="bulleted-list"><li style="list-style-type:circle">전체 입력 시퀀스에 대한 Self-Attention 적용</li></ul></li></ul><ul id="25af5941-8cd1-4084-a5e8-e536a9ef0754" class="bulleted-list"><li style="list-style-type:disc"><strong>디코더</strong>: 단방향(Left-to-Right) 처리<ul id="d7570611-bf1b-46dd-af51-deebc88cc709" class="bulleted-list"><li style="list-style-type:circle">마스크된 Self-Attention으로 이전 토큰만 참조</li></ul><ul id="c815726e-f832-466d-9688-6e8100e3747c" class="bulleted-list"><li style="list-style-type:circle">자기회귀적(Autoregressive) 생성 모델</li></ul></li></ul><p id="2024d778-1cdc-80d5-961a-c16fb27cb7dc" class="">
</p><p id="2024d778-1cdc-8039-9878-cd5d0e118a9d" class="">
</p><p id="2024d778-1cdc-80d0-9732-e4a46c02db6d" class="">
</p><h2 id="01afb9dd-0557-4b07-8f34-a192858a99c6" class="">5. 태스크 적합성</h2><h3 id="821cc6bc-6b44-4c87-8e49-48527c5ae3c8" class="">Transformer</h3><ul id="379bfc7d-aedd-49d9-8fee-dd21aa0c2d9c" class="bulleted-list"><li style="list-style-type:disc"><strong>생성(Generation) 태스크에 강점</strong>:<ul id="549ff01d-289f-44c9-abff-f7e873851953" class="bulleted-list"><li style="list-style-type:circle">기계 번역</li></ul><ul id="005bfb0a-e102-4e69-9b22-bcefee2f28b4" class="bulleted-list"><li style="list-style-type:circle">텍스트 요약</li></ul><ul id="682c9b18-463f-4348-a819-4637c67f5a4e" class="bulleted-list"><li style="list-style-type:circle">대화 생성</li></ul><ul id="47eaf9a4-c3cc-40ee-b5f0-5e14e6ae1bcb" class="bulleted-list"><li style="list-style-type:circle">이미지 캡션 생성</li></ul></li></ul><h3 id="f1720420-339a-48e8-8ad2-d532dbfdbfe1" class="">BERT (비교를 위해)</h3><ul id="0fad9bcf-544b-4043-88ca-0fa321fcf614" class="bulleted-list"><li style="list-style-type:disc"><strong>이해(Understanding) 태스크에 강점</strong>:<ul id="44b62973-98a5-499b-8c07-c3a1fe7bbd24" class="bulleted-list"><li style="list-style-type:circle">텍스트 분류(감성 분석, 주제 분류)</li></ul><ul id="78f6b16b-be70-41e1-a46e-d411473ce9c1" class="bulleted-list"><li style="list-style-type:circle">개체명 인식(Named Entity Recognition)</li></ul><ul id="a97104ec-4402-4ce1-b530-ab544643003c" class="bulleted-list"><li style="list-style-type:circle">질의응답(Question Answering)</li></ul><ul id="47be2bc2-cfa7-4cd9-9271-4789472b5222" class="bulleted-list"><li style="list-style-type:circle">자연어 추론(Natural Language Inference)</li></ul><ul id="38ebe090-cfe4-42f8-a72a-c06f17d0746c" class="bulleted-list"><li style="list-style-type:circle">의미적 유사도(Semantic Similarity)</li></ul></li></ul></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>