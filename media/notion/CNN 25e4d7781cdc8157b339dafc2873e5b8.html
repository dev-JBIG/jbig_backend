<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>CNN</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.collection-content td {
	white-space: pre-wrap;
	word-break: break-word;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

blockquote.quote-large {
	font-size: 1.25em;
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray {
	color: rgba(142, 139, 134, 1);
	fill: rgba(142, 139, 134, 1);
}
.highlight-brown {
	color: rgba(182, 137, 101, 1);
	fill: rgba(182, 137, 101, 1);
}
.highlight-orange {
	color: rgba(213, 128, 59, 1);
	fill: rgba(213, 128, 59, 1);
}
.highlight-yellow {
	color: rgba(229, 178, 68, 1);
	fill: rgba(229, 178, 68, 1);
}
.highlight-teal {
	color: rgba(85, 167, 124, 1);
	fill: rgba(85, 167, 124, 1);
}
.highlight-blue {
	color: rgba(35, 131, 226, 1);
	fill: rgba(35, 131, 226, 1);
}
.highlight-purple {
	color: rgba(181, 119, 214, 1);
	fill: rgba(181, 119, 214, 1);
}
.highlight-pink {
	color: rgba(219, 105, 153, 1);
	fill: rgba(219, 105, 153, 1);
}
.highlight-red {
	color: rgba(229, 100, 88, 1);
	fill: rgba(229, 100, 88, 1);
}
.highlight-default_background {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray_background {
	background: rgba(240, 239, 237, 1);
}
.highlight-brown_background {
	background: rgba(245, 237, 233, 1);
}
.highlight-orange_background {
	background: rgba(251, 235, 222, 1);
}
.highlight-yellow_background {
	background: rgba(249, 243, 220, 1);
}
.highlight-teal_background {
	background: rgba(232, 241, 236, 1);
}
.highlight-blue_background {
	background: rgba(232, 242, 250, 1);
}
.highlight-purple_background {
	background: rgba(243, 235, 249, 1);
}
.highlight-pink_background {
	background: rgba(250, 233, 241, 1);
}
.highlight-red_background {
	background: rgba(252, 233, 231, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(142, 139, 134, 1);
	fill: rgba(142, 139, 134, 1);
}
.block-color-brown {
	color: rgba(182, 137, 101, 1);
	fill: rgba(182, 137, 101, 1);
}
.block-color-orange {
	color: rgba(213, 128, 59, 1);
	fill: rgba(213, 128, 59, 1);
}
.block-color-yellow {
	color: rgba(229, 178, 68, 1);
	fill: rgba(229, 178, 68, 1);
}
.block-color-teal {
	color: rgba(85, 167, 124, 1);
	fill: rgba(85, 167, 124, 1);
}
.block-color-blue {
	color: rgba(35, 131, 226, 1);
	fill: rgba(35, 131, 226, 1);
}
.block-color-purple {
	color: rgba(181, 119, 214, 1);
	fill: rgba(181, 119, 214, 1);
}
.block-color-pink {
	color: rgba(219, 105, 153, 1);
	fill: rgba(219, 105, 153, 1);
}
.block-color-red {
	color: rgba(229, 100, 88, 1);
	fill: rgba(229, 100, 88, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(240, 239, 237, 1);
}
.block-color-brown_background {
	background: rgba(245, 237, 233, 1);
}
.block-color-orange_background {
	background: rgba(251, 235, 222, 1);
}
.block-color-yellow_background {
	background: rgba(249, 243, 220, 1);
}
.block-color-teal_background {
	background: rgba(232, 241, 236, 1);
}
.block-color-blue_background {
	background: rgba(232, 242, 250, 1);
}
.block-color-purple_background {
	background: rgba(243, 235, 249, 1);
}
.block-color-pink_background {
	background: rgba(250, 233, 241, 1);
}
.block-color-red_background {
	background: rgba(252, 233, 231, 1);
}
.select-value-color-default { background-color: rgba(42, 28, 0, 0.07); }
.select-value-color-gray { background-color: rgba(28, 19, 1, 0.11); }
.select-value-color-brown { background-color: rgba(127, 51, 0, 0.156); }
.select-value-color-orange { background-color: rgba(196, 88, 0, 0.203); }
.select-value-color-yellow { background-color: rgba(209, 156, 0, 0.282); }
.select-value-color-green { background-color: rgba(0, 96, 38, 0.156); }
.select-value-color-blue { background-color: rgba(0, 99, 174, 0.172); }
.select-value-color-purple { background-color: rgba(92, 0, 163, 0.141); }
.select-value-color-pink { background-color: rgba(183, 0, 78, 0.152); }
.select-value-color-red { background-color: rgba(206, 24, 0, 0.164); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="25e4d778-1cdc-8157-b339-dafc2873e5b8" class="page sans"><header><h1 class="page-title">CNN</h1><p class="page-description"></p></header><div class="page-body"><h2 id="25e4d778-1cdc-8193-a606-d00eb78b9385" class=""><strong>1. 합성곱 신경망의 등장</strong></h2><p id="25e4d778-1cdc-8129-a701-fe065eacc8d2" class="">합성곱 신경망은 이미지 처리에 탁월한 성능을 보이는 신경망입니다. 이미지 처리를 하기 위해서 앞서 배운 다층 퍼셉트론을 사용할 수는 있지만 한계가 있었습니다. 예를 들어, 알파벳 손글씨를 분류하는 어떤 문제가 있다고 해봅시다. 아래의 그림은 알파벳 Y를 비교적 정자로 쓴 손글씨와 다소 휘갈겨 쓴 손글씨 두 개를 2차원 텐서인 행렬로 표현한 것입니다.</p><figure id="25e4d778-1cdc-81aa-8b4f-f8a49cf510a6" class="image"><a href="https://wikidocs.net/images/page/64066/conv0.png"><img src="https://wikidocs.net/images/page/64066/conv0.png"/></a></figure><p id="25e4d778-1cdc-8187-9cf9-dadbf2d86558" class="">사람이 보기에는 두 그림 모두 알파벳 Y로 손쉽게 판단이 가능하지만, 기계가 보기에는 각 픽셀마다 가진 값이 대부분 상이하므로 사실상 다른 값을 가진 입력입니다. 그런데 이미지라는 것은 위와 같이 같은 대상이라도 휘어지거나, 이동되었거나, 방향이 뒤틀렸거나 등 다양한 변형이 존재합니다. 다층 퍼셉트론은 몇 가지 픽셀만 값이 달라져도 민감하게 예측에 영향을 받는다는 단점이 있습니다.</p><p id="25e4d778-1cdc-8112-9c29-d9f8a7e593a8" class="">좀 더 구체적으로 보겠습니다. 위 손글씨를 다층 퍼셉트론으로 분류한다고 하면, 이미지를 1차원 텐서인 벡터로 변환하고 다층 퍼셉트론의 입력층으로 사용해야 합니다. 두번째 손글씨를 다층 퍼셉트론으로 분류하기 위해서 벡터로 바꾸면 다음과 같습니다.</p><figure id="25e4d778-1cdc-8179-b1d6-dfa4c4c89f8f" class="image"><a href="https://wikidocs.net/images/page/64066/conv1.png"><img src="https://wikidocs.net/images/page/64066/conv1.png"/></a></figure><p id="25e4d778-1cdc-8122-a3a9-d315cfe9cda5" class="">1차원으로 변환된 결과는 사람이 보기에도 이게 원래 어떤 이미지였는지 알아보기가 어렵습니다. 이는 기계도 마찬가지 입니다. 위와 같이 결과는 변환 전에 가지고 있던 공간적인 구조(spatial structure) 정보가 유실된 상태입니다. 여기서 공간적인 구조 정보라는 것은 거리가 가까운 어떤 픽셀들끼리는 어떤 연관이 있고, 어떤 픽셀들끼리는 값이 비슷하거나 등을 포함하고 있습니다. 결국 이미지의 공간적인 구조 정보를 보존하면서 학습할 수 있는 방법이 필요해졌고, 이를 위해 합성곱 신경망을 사용합니다.</p><p id="25e4d778-1cdc-8146-84e3-db9d235b8ca6" class="">
</p><p id="25e4d778-1cdc-815f-9d28-f4500980bf54" class="">쉽게 이해할 수 있도록, CNN의 작동 원리와 이를 설명하는 데 필요한 기본 용어들을 하나씩 정리해보겠습니다.</p><hr id="25e4d778-1cdc-8166-88c6-cf8e1361fb61"/><h3 id="25e4d778-1cdc-816a-8c92-fc2b88a5ffcb" class="">CNN의 기본 개념</h3><p id="25e4d778-1cdc-81a1-bb95-e99b3e7c8dea" class="">CNN의 목표는 이미지에서 중요한 패턴을 찾아내는 것입니다. 예를 들어, 고양이 사진을 보면 CNN은 고양이의 귀나 눈 모양 등 특정 패턴을 감지하고 이를 학습하여 &quot;이 이미지는 고양이이다&quot;라고 판단하게 됩니다. 이 과정에서 CNN은 이미지 전체를 한꺼번에 보기보다는, 이미지의 일부분씩 작은 영역을 관찰하여 점차 전체를 이해하는 방식으로 학습합니다.</p><figure id="25e4d778-1cdc-81d2-a99d-c83ff6fa3559" class="image"><a href="image%2050.png"><img style="width:384.953125px" src="image%2050.png"/></a></figure><h3 id="25e4d778-1cdc-816a-8a92-fc2c6c52ec4e" class="">CNN을 구성하는 기본 용어들</h3><h3 id="25e4d778-1cdc-81fe-9815-c2777bcb9a80" class="">1. <strong>Convolution (합성곱)</strong></h3><ul id="25e4d778-1cdc-81d9-9f2b-d7c58df805f7" class="bulleted-list"><li style="list-style-type:disc"><strong>정의</strong>: 합성곱은 이미지를 작은 창(필터)으로 훑어가면서 중요한 특징을 추출하는 연산입니다.</li></ul><ul id="25e4d778-1cdc-819d-948d-ce11014e60f8" class="bulleted-list"><li style="list-style-type:disc"><strong>필터 (Filter)</strong>: 필터는 이미지의 작은 영역을 관찰하는 작은 창이라고 할 수 있습니다. 보통 3x3 또는 5x5 크기의 정사각형 모양입니다. 커널이라고도 부릅니다.</li></ul><ul id="25e4d778-1cdc-8179-8547-c1c07efea053" class="bulleted-list"><li style="list-style-type:disc"><strong>예시</strong>: 필터가 이미지의 한 부분을 덮고, 이 부분의 색깔이나 모양이 필터와 얼마나 일치하는지 계산합니다. 이 계산 결과는 새로운 이미지(특징 맵)에 추가됩니다. CNN은 이 필터를 사용하여 엣지, 질감 같은 이미지를 구성하는 작은 특징들을 추출합니다.<figure id="25e4d778-1cdc-817a-a48d-d44b574a2cfd" class="image"><a href="image%2051.png"><img style="width:356.984375px" src="image%2051.png"/></a></figure><figure id="25e4d778-1cdc-81df-8542-edc8287e54d3" class="image"><a href="https://raw.githubusercontent.com/iamaaditya/iamaaditya.github.io/master/images/conv_arithmetic/full_padding_no_strides_transposed.gif"><img src="https://raw.githubusercontent.com/iamaaditya/iamaaditya.github.io/master/images/conv_arithmetic/full_padding_no_strides_transposed.gif"/></a></figure><figure id="25e4d778-1cdc-81b8-9a5e-c23674973bd1" class="image"><a href="image%2052.png"><img style="width:356.984375px" src="image%2052.png"/></a></figure><figure id="25e4d778-1cdc-810d-9421-cf62e1c46d9f" class="image"><a href="image%2053.png"><img style="width:357px" src="image%2053.png"/></a></figure></li></ul><h3 id="25e4d778-1cdc-8151-ab06-fd779c15f4c0" class="">2. <strong>Feature Map (특징 맵)</strong></h3><ul id="25e4d778-1cdc-8193-9d47-ed249b6d7d27" class="bulleted-list"><li style="list-style-type:disc"><strong>정의</strong>: 합성곱 과정을 통해 만들어진 이미지의 새로운 형태로, 원본 이미지의 특징이 잘 드러난 맵입니다.</li></ul><ul id="25e4d778-1cdc-8190-89dc-e76241abfaed" class="bulleted-list"><li style="list-style-type:disc"><strong>예시</strong>: 고양이 사진의 경우, 특정 필터가 고양이의 귀 모양을 잘 감지했다면 그 필터의 결과(특징 맵)에는 귀 모양에 해당하는 부분만 강조되어 나타납니다.<figure id="25e4d778-1cdc-8180-8826-ddda3c688060" class="image"><a href="image%2054.png"><img style="width:356.953125px" src="image%2054.png"/></a></figure></li></ul><h3 id="25e4d778-1cdc-817f-8579-d51759c6e171" class="">3. <strong>Stride (스트라이드)</strong></h3><ul id="25e4d778-1cdc-8161-bce5-d23fd7891468" class="bulleted-list"><li style="list-style-type:disc"><strong>정의</strong>: 필터가 이미지 위를 이동하는 간격을 의미합니다.</li></ul><ul id="25e4d778-1cdc-8105-9c10-ff67e3c2bc87" class="bulleted-list"><li style="list-style-type:disc"><strong>예시</strong>: 스트라이드가 1이면 필터가 한 칸씩 이동하고, 스트라이드가 2이면 두 칸씩 이동합니다. 스트라이드가 커질수록 필터가 덮는 영역이 커지므로, 특징 맵 크기는 작아집니다.<figure id="25e4d778-1cdc-81bc-b4d5-e1777e0ecdf7" class="image"><a href="image%2055.png"><img style="width:384.96875px" src="image%2055.png"/></a></figure><figure id="25e4d778-1cdc-81ee-9d7a-ded472783c35" class="image"><a href="https://cdn-images-1.medium.com/max/1200/1*BMngs93_rm2_BpJFH2mS0Q.gif"><img src="https://cdn-images-1.medium.com/max/1200/1*BMngs93_rm2_BpJFH2mS0Q.gif"/></a></figure></li></ul><h3 id="25e4d778-1cdc-812b-b961-e35f6f6eb79e" class="">4. <strong>Padding (패딩)</strong></h3><ul id="25e4d778-1cdc-8164-99de-d96fadc7a1bf" class="bulleted-list"><li style="list-style-type:disc"><strong>정의</strong>: 이미지 가장자리에 0으로 된 픽셀을 추가하여 이미지 크기를 유지하는 작업입니다.</li></ul><ul id="25e4d778-1cdc-81eb-b3a6-d83ce7ee19f1" class="bulleted-list"><li style="list-style-type:disc"><strong>이유</strong>: 필터가 이미지의 가장자리를 처리할 때 정보가 부족할 수 있습니다. 패딩은 이러한 문제를 해결하기 위해 사용됩니다.</li></ul><ul id="25e4d778-1cdc-818d-88ff-c77545302b1f" class="bulleted-list"><li style="list-style-type:disc"><strong>예시</strong>: 고양이 귀가 이미지의 가장자리에 위치한 경우 패딩이 없으면 이 부분이 분석되지 않지만, 패딩을 통해 이 부분까지 확인할 수 있습니다.</li></ul><figure id="25e4d778-1cdc-810a-9cb0-eff916cdc36b" class="image"><a href="https://miro.medium.com/v2/resize:fit:640/format:webp/1*O06nY1U7zoP4vE5AZEnxKA.gif"><img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*O06nY1U7zoP4vE5AZEnxKA.gif"/></a></figure><h3 id="25e4d778-1cdc-8124-baba-fc3386114dd4" class="">5. <strong>Pooling (풀링)</strong></h3><ul id="25e4d778-1cdc-81ae-9e93-ff17d0006700" class="bulleted-list"><li style="list-style-type:disc"><strong>정의</strong>: 풀링은 특징 맵의 크기를 줄이는 과정입니다. 이는 중요한 특징은 유지하면서 불필요한 정보는 줄이는 역할을 합니다.</li></ul><ul id="25e4d778-1cdc-813b-9097-ebe5903d820f" class="bulleted-list"><li style="list-style-type:disc"><strong>종류</strong>: 주로 <strong>Max Pooling</strong>과 <strong>Average Pooling</strong>이 사용됩니다.<ul id="25e4d778-1cdc-81ad-93d6-e28e69a41754" class="bulleted-list"><li style="list-style-type:circle"><strong>Max Pooling</strong>: 특정 영역에서 가장 큰 값을 선택하여 주요 특징을 강조합니다.</li></ul><ul id="25e4d778-1cdc-8113-8631-ec35cdf733fa" class="bulleted-list"><li style="list-style-type:circle"><strong>Average Pooling</strong>: 특정 영역의 평균값을 선택하여 데이터를 부드럽게 만듭니다.</li></ul></li></ul><ul id="25e4d778-1cdc-8168-a9bf-fff3fb0924ae" class="bulleted-list"><li style="list-style-type:disc"><strong>예시</strong>: Max Pooling을 통해 고양이 눈 모양의 엣지를 강조하는 부분만 남기고 주변 불필요한 정보를 줄일 수 있습니다.<figure id="25e4d778-1cdc-819b-a9bb-e6a51f3de10b" class="image"><a href="image%2056.png"><img style="width:356.984375px" src="image%2056.png"/></a></figure></li></ul><h3 id="25e4d778-1cdc-8147-aa9e-e253243c58ef" class="">6. <strong>Flatten (평탄화)</strong></h3><ul id="25e4d778-1cdc-812d-8323-e5204804b675" class="bulleted-list"><li style="list-style-type:disc"><strong>정의</strong>: 2차원으로 된 특징 맵을 1차원으로 펼치는 과정입니다. 이를 통해 완전 연결층(FC Layer)에 전달할 수 있습니다.</li></ul><ul id="25e4d778-1cdc-8115-bd6c-dd8c82c48d42" class="bulleted-list"><li style="list-style-type:disc"><strong>예시</strong>: 평탄화 과정을 통해 CNN이 추출한 여러 특징들이 한 줄로 나열되어 마지막 분류 작업을 할 수 있게 됩니다.<figure id="25e4d778-1cdc-8173-bc71-cd96d14026d4" class="image"><a href="image%2057.png"><img style="width:384.984375px" src="image%2057.png"/></a></figure></li></ul><h3 id="25e4d778-1cdc-8182-ac2a-e523a5d53a70" class="">7. <strong>Fully Connected Layer (완전 연결층)</strong></h3><ul id="25e4d778-1cdc-81fc-9909-e3064fdf1e1f" class="bulleted-list"><li style="list-style-type:disc"><strong>정의</strong>: CNN의 마지막 부분으로, 추출된 특징을 기반으로 최종 분류를 수행합니다.</li></ul><ul id="25e4d778-1cdc-81b0-9558-e56b823363dd" class="bulleted-list"><li style="list-style-type:disc"><strong>예시</strong>: 고양이와 개를 구분하는 CNN이라면, 마지막 FC Layer에서 각 특징을 조합해 고양이일 확률과 개일 확률을 계산하여 최종적으로 어떤 동물인지 예측합니다.</li></ul><h3 id="25e4d778-1cdc-8145-a4b2-db2dc2bc7aae" class="">8. <strong>Activation Function (활성화 함수)</strong></h3><ul id="25e4d778-1cdc-8195-a409-c62ba30633a4" class="bulleted-list"><li style="list-style-type:disc"><strong>정의</strong>: 각 레이어의 출력값에 비선형성을 추가하여 모델이 더 복잡한 패턴을 학습하도록 돕는 함수입니다.</li></ul><ul id="25e4d778-1cdc-81f8-8fd3-e0e3043cea58" class="bulleted-list"><li style="list-style-type:disc"><strong>종류</strong>: CNN에서는 주로 **ReLU (Rectified Linear Unit)**가 사용됩니다.</li></ul><ul id="25e4d778-1cdc-81c2-b509-faa40abcbdc3" class="bulleted-list"><li style="list-style-type:disc"><strong>예시</strong>: ReLU는 양수인 값은 그대로 전달하고, 음수인 값은 0으로 바꿔줍니다. 이를 통해 모델이 이미지의 중요한 특징에 더 집중할 수 있도록 합니다.</li></ul><figure id="25e4d778-1cdc-81a9-bf9c-f6f4b3f1dcb5" class="image"><a href="image%2058.png"><img style="width:217px" src="image%2058.png"/></a></figure><hr id="25e4d778-1cdc-819e-ad15-ea644b658277"/><h3 id="25e4d778-1cdc-81e2-95fa-fd4c6fdfd995" class="">CNN의 이해를 돕기 위한 짧은 영상</h3><figure id="25e4d778-1cdc-81ac-aed1-fb5001e394ef"><div class="source"><a href="https://www.youtube.com/shorts/9zzZZjYkLV4">https://www.youtube.com/shorts/9zzZZjYkLV4</a></div></figure><hr id="25e4d778-1cdc-815b-b3da-cea2c26c9135"/><h3 id="25e4d778-1cdc-81f6-be74-e40fc53993b2" class="">CNN의 전체 구조</h3><p id="25e4d778-1cdc-81dc-a247-fbe5dff1d51b" class="">CNN은 크게 두 가지 단계로 구성됩니다:</p><ol type="1" id="25e4d778-1cdc-81c4-bf6e-cc58e8a1635a" class="numbered-list" start="1"><li><strong>특징 추출(Feature Extraction) 단계</strong>: Convolution과 Pooling을 통해 이미지를 분석하고 중요한 특징을 추출합니다.</li></ol><ol type="1" id="25e4d778-1cdc-8133-b480-f02e073189b7" class="numbered-list" start="2"><li><strong>분류(Classification) 단계</strong>: Flatten과 Fully Connected Layer를 통해 특징들을 조합하고, 이미지가 어떤 클래스(예: 고양이, 개, 사람 등)에 속하는지 예측합니다.</li></ol><figure id="25e4d778-1cdc-8166-994f-e5aa3323db1e" class="image"><a href="image%2059.png"><img style="width:384.984375px" src="image%2059.png"/></a></figure><p id="25e4d778-1cdc-81b6-b279-f90aa5be9c4d" class="">이 구조 덕분에 CNN은 이미지 내에서 특정 패턴이나 객체를 인식하는 데 매우 효과적입니다.</p><p id="25e4d778-1cdc-813a-8894-c50cafdb86a7" class="">
</p><hr id="25e4d778-1cdc-81ed-9784-d1ba94323c77"/><h3 id="25e4d778-1cdc-8193-9e18-c23be12b5e8c" class="">문제 1</h3><p id="25e4d778-1cdc-8113-b247-e0c7e4a0603a" class=""><strong>Q</strong>: 다층 퍼셉트론(Multi-Layer Perceptron) 대신 이미지 분류에 합성곱 신경망(CNN)을 사용하는 이유는 무엇인가요?</p><ul id="25e4d778-1cdc-81b0-9f19-c157b4cceceb" class="toggle"><li><details open=""><summary>정답</summary><p id="25e4d778-1cdc-81ac-8397-dde988986aa2" class=""> 다층 퍼셉트론은 이미지를 1차원으로 변환해야 하므로 이미지의 공간적 구조(spatial structure) 정보가 유실됩니다. CNN은 공간적 구조 정보를 보존하며 학습할 수 있어, 이미지 내에서 객체의 위치나 형태의 차이에 강건한 성능을 보입니다.</p></details></li></ul><hr id="25e4d778-1cdc-813f-86bb-c52e24a10b95"/><h3 id="25e4d778-1cdc-818a-8673-c389022c3fdf" class="">문제 2</h3><p id="25e4d778-1cdc-81dc-affb-de63a7cf55be" class=""><strong>Q</strong>: 합성곱(Convolution) 연산에서 필터(Filter)의 역할은 무엇인가요?</p><ul id="25e4d778-1cdc-81ec-b538-c103485707c6" class="toggle"><li><details open=""><summary>정답</summary><p id="25e4d778-1cdc-81e3-8fe3-e5eb7adace6a" class="">필터는 이미지의 작은 영역을 훑으면서 중요한 특징(엣지, 텍스처 등)을 추출하는 역할을 합니다. CNN은 여러 필터를 사용하여 이미지의 다양한 패턴을 감지하고 이를 바탕으로 특징 맵을 만듭니다.</p></details></li></ul><hr id="25e4d778-1cdc-818c-ac55-e5a9eaeaec07"/><h3 id="25e4d778-1cdc-8189-acc1-f927ba831600" class="">문제 3</h3><p id="25e4d778-1cdc-8151-8c24-ca13c9bdcc95" class=""><strong>Q</strong>: Pooling(풀링)을 사용하는 주된 이유는 무엇이며, 주로 사용하는 풀링 방식 두 가지는 무엇인가요?</p><ul id="25e4d778-1cdc-8162-ae5f-fc9963752d32" class="toggle"><li><details open=""><summary>정답</summary><p id="25e4d778-1cdc-8110-a1ef-d438ccf09f1f" class="">Pooling은 특징 맵의 크기를 줄여 연산량을 감소시키고, 중요한 특징을 유지하면서 불필요한 정보를 줄이는 역할을 합니다. 주로 사용하는 풀링 방식은 <strong>Max Pooling</strong>과 <strong>Average Pooling</strong>으로, Max Pooling은 영역 내 가장 큰 값을, Average Pooling은 평균값을 선택하여 특징을 추출합니다.</p></details></li></ul><hr id="25e4d778-1cdc-8158-8345-e180949e068d"/><h2 id="25e4d778-1cdc-8154-9ea2-fe7c36fa224a" class="">코드</h2><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="25e4d778-1cdc-811d-b401-ed4c82029f1f" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms

# transform 정의
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Mnist Data(흑백사진) 불러오기
trainset = torchvision.datasets.MNIST(root=&#x27;./data&#x27;, train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)

testset = torchvision.datasets.MNIST(root=&#x27;./data&#x27;, train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)

# CNN 모델 정의
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        
        # 흑백사진이므로 입력채널은 1, 컬러사진이라면 RGB의 정보가 있으므로 입력채널은 3
        # 첫 번째 Convolutional Layer (입력 채널: 1, 출력 채널: 32, 커널 크기: 3x3)
        # 필터(커널) 크기가 3x3이며, 이 필터가 입력 이미지를 탐색하면서 특징을 추출합니다.
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)
        
        # 두 번째 Convolutional Layer (입력 채널: 32, 출력 채널: 64, 커널 크기: 3x3)
        # 두 번째 합성곱 층은 첫 번째 층의 출력에서 더 복잡한 특징을 추출합니다.
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        
        # Max Pooling Layer (커널 크기: 2x2)
        # Max Pooling을 통해 크기를 줄이며, 주요 특징을 남기고 불필요한 정보를 제거합니다.
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        
        # 첫 번째 Fully Connected Layer
        # 이미지의 Flatten된 특징을 받아 분류를 위한 계산을 진행합니다.
        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # 이미지 크기가 28x28에서 풀링으로 인해 7x7로 축소됩니다.
        
        # 두 번째 Fully Connected Layer (출력 클래스: 10)
        # 마지막 분류를 위해 각 숫자(0~9)에 대한 확률을 출력합니다.
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        # 1. 첫 번째 합성곱 연산
        x = self.conv1(x)  # Convolution 연산 수행
        x = torch.relu(x)  # ReLU 활성화 함수 적용
        x = self.pool(x)   # Max Pooling으로 이미지 크기 축소 (28x28 -&gt; 14x14)
        
        # 2. 두 번째 합성곱 연산
        x = self.conv2(x)  # Convolution 연산 수행
        x = torch.relu(x)  # ReLU 활성화 함수 적용
        x = self.pool(x)   # Max Pooling으로 이미지 크기 축소 (14x14 -&gt; 7x7)
        
        # 3. Flatten (평탄화)
        x = x.view(-1, 64 * 7 * 7)  # 2D 특성 맵을 1D로 변환하여 Fully Connected Layer에 전달
        
        # 4. 첫 번째 Fully Connected Layer
        x = self.fc1(x)  # 첫 번째 완전 연결 층 적용
        x = torch.relu(x)  # ReLU 활성화 함수 적용
        
        # 5. 두 번째 Fully Connected Layer (출력층)
        x = self.fc2(x)  # 최종 출력층 적용
        
        return x

# # 모델, 손실 함수, 옵티마이저 초기화
# model = SimpleCNN()
# criterion = nn.CrossEntropyLoss()  # 다중 클래스 분류를 위한 손실 함수
# optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam 옵티마이저 사용

# # 모델 훈련 루프
# num_epochs = 5
# for epoch in range(num_epochs):
#     running_loss = 0.0
#     for inputs, labels in trainloader:
#         optimizer.zero_grad()  # 기울기 초기화
#         outputs = model(inputs)  # 모델 예측값
#         loss = criterion(outputs, labels)  # 손실 계산
#         loss.backward()  # 역전파 수행
#         optimizer.step()  # 가중치 업데이트
#         running_loss += loss.item()
    
#     print(f&#x27;Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}&#x27;)

# print(&#x27;Training complete&#x27;)

# # 모델 테스트
# correct = 0
# total = 0
# with torch.no_grad():
#     for inputs, labels in testloader:
#         outputs = model(inputs)
#         _, predicted = torch.max(outputs, 1)
#         total += labels.size(0)
#         correct += (predicted == labels).sum().item()

# print(f&#x27;Accuracy on test set: {100 * correct / total:.2f}%&#x27;)
</code></pre><p id="25e4d778-1cdc-81c1-bc5f-e642cd51a027" class="">
</p><p id="25e4d778-1cdc-81e6-8b3f-e6d2b8e0ba37" class="">
</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>