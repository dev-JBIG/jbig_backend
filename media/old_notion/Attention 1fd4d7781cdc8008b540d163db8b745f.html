<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Attention </title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(50, 48, 44, 1);
}
.highlight-gray {
	color: rgba(115, 114, 110, 1);
	fill: rgba(115, 114, 110, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(205, 60, 58, 1);
	fill: rgba(205, 60, 58, 1);
}
.highlight-default_background {
	color: rgba(50, 48, 44, 1);
}
.highlight-gray_background {
	background: rgba(248, 248, 247, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(248, 243, 252, 1);
}
.highlight-pink_background {
	background: rgba(252, 241, 246, 1);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(115, 114, 110, 1);
	fill: rgba(115, 114, 110, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(205, 60, 58, 1);
	fill: rgba(205, 60, 58, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(248, 248, 247, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(248, 243, 252, 1);
}
.block-color-pink_background {
	background: rgba(252, 241, 246, 1);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-default { background-color: rgba(84, 72, 49, 0.08); }
.select-value-color-gray { background-color: rgba(84, 72, 49, 0.15); }
.select-value-color-brown { background-color: rgba(210, 162, 141, 0.35); }
.select-value-color-orange { background-color: rgba(224, 124, 57, 0.27); }
.select-value-color-yellow { background-color: rgba(236, 191, 66, 0.39); }
.select-value-color-green { background-color: rgba(123, 183, 129, 0.27); }
.select-value-color-blue { background-color: rgba(93, 165, 206, 0.27); }
.select-value-color-purple { background-color: rgba(168, 129, 197, 0.27); }
.select-value-color-pink { background-color: rgba(225, 136, 179, 0.27); }
.select-value-color-red { background-color: rgba(244, 171, 159, 0.4); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="1fd4d778-1cdc-8008-b540-d163db8b745f" class="page sans"><header><h1 class="page-title">Attention </h1><p class="page-description"></p></header><div class="page-body"><hr id="1fd4d778-1cdc-8000-b44e-e7ce79e4a180"/><p id="1fd4d778-1cdc-8038-a07e-e0d609bbb4f9" class=""><strong>Seq2Seq의 문제점</strong></p><p id="1fd4d778-1cdc-80a9-88fe-f207c8663552" class="">Seq2Seq 모델은 인코더와 디코더로 구성된 훌륭한 구조를 가지고 있지만, 긴 문장을 처리할 때 여전히 한 가지 큰 문제가 남아 있었습니다. 인코더가 긴 문장을 요약해 하나의 벡터로 변환할 때, 중요한 정보가 손실될 가능성이 있다는 점이었습니다.</p><p id="1fd4d778-1cdc-809c-a24a-d29fd81817da" class="">예를 들어, &quot;오늘은 날씨가 좋아서 산책을 할까 하는데, 저녁에는 친구와 만나서 저녁을 먹을까 생각 중이야&quot;라는 긴 문장이 있다면, 인코더가 모든 정보를 하나의 벡터로 요약하는 과정에서 &quot;저녁&quot;이나 &quot;친구와 만남&quot; 같은 중요한 세부 정보가 손실될 수 있습니다.</p><p id="1fd4d778-1cdc-8006-97ee-fbc0a5ba972a" class="">Attention은 간단히 말해, <strong>디코더가 출력 문장을 생성할 때 입력 문장에서 어느 부분에 주목해야 하는지 알려주는 기술</strong>입니다. Seq2Seq 모델이 모든 입력 문장을 하나의 벡터로 요약했다면, Attention은 입력 문장의 각 단어를 디코더가 필요할 때마다 선택적으로 참고할 수 있도록 합니다.</p><p id="1fd4d778-1cdc-80b9-9659-c383fb7b9b2c" class="">
</p><p id="1fd4d778-1cdc-8092-be38-eecb4e936dfb" class="">예를 들어, </p><p id="1fd4d778-1cdc-803c-a69d-f360eccfef85" class="">&quot;I am a student&quot;를 번역할 때 &quot;student&quot;를 생성하려고 한다면, </p><p id="1fd4d778-1cdc-8055-ba7e-d46cc67e2d06" class="">&quot;I&quot;나 &quot;am&quot;보다는 &quot;student&quot;와 관련이 높은 단어에 더 집중하게 됩니다.</p><hr id="1fd4d778-1cdc-80ed-a938-e60b457b06c0"/><p id="1fd4d778-1cdc-807c-a716-fac9de81356c" class=""><strong>어떻게 작동하나요?</strong></p><p id="1fd4d778-1cdc-8051-bfcf-cf2f870b5db9" class="">Attention의 작동 방식은 다음과 같습니다.</p><ol type="1" id="1fd4d778-1cdc-8006-b2c3-c969bba084d6" class="numbered-list" start="1"><li><strong>Query, Key, Value로 나누기</strong><p id="bae38574-9553-4565-9a57-9369f511a346" class="">Attention 메커니즘에서는 입력 문장을 다음 세 가지로 분류합니다:</p><ul id="543d07cf-5d64-4cfb-826a-1ec48be959c3" class="bulleted-list"><li style="list-style-type:disc"><strong>Query (Q):</strong> 디코더에서 현재 생성하려는 단어에 대한 정보.</li></ul><ul id="f702900c-1195-4ebe-a97e-0d960dd15d70" class="bulleted-list"><li style="list-style-type:disc"><strong>Key (K):</strong> 입력 문장의 각 단어가 가진 위치 정보.</li></ul><ul id="e6050114-f34e-42fb-be67-019021fd65a2" class="bulleted-list"><li style="list-style-type:disc"><strong>Value (V):</strong> 입력 문장의 각 단어가 가진 실제 내용 정보.</li></ul></li></ol><ol type="1" id="1fd4d778-1cdc-8064-b564-ffcd6f851105" class="numbered-list" start="2"><li><strong>어텐션 스코어 (유사도 계산)</strong><p id="227c334b-1474-41c6-ac73-71c2522fe2a7" class="">Query와 Key 간의 유사도(dot product)를 계산합니다.</p><ul id="a617cba7-be19-4f5d-9fcc-87b0b81c04d9" class="bulleted-list"><li style="list-style-type:disc">이 유사도는 현재 출력 단어를 생성할 때, 입력 문장의 각 단어가 얼마나 중요한지를 나타냅니다.</li></ul><p id="1b9890f5-05b9-4264-9f5f-f8a67b8625e3" class="">예:</p><p id="6f0964a4-a754-4758-b535-ac5db4dbe9ea" class="">Query가 &quot;student&quot;를 생성하려고 하면, Key와의 유사도를 계산해 &quot;student&quot;에 가까운 단어에 높은 점수를 부여합니다.</p></li></ol><p id="1fd4d778-1cdc-805e-bfdf-c1c1701026ac" class="">
</p><figure id="1fd4d778-1cdc-80e7-879d-cde6bfbf8edc" class="image"><a href="image%2069.png"><img style="width:567.984375px" src="image%2069.png"/></a></figure><ol type="1" id="1fd4d778-1cdc-8013-9350-d28a990a09e4" class="numbered-list" start="3"><li><strong>어텐션 분포(Attention Distribution) 계산 (Softmax)</strong><p id="b25207eb-9608-4291-b12e-739e012a1635" class="">유사도 점수에 <strong>Softmax 함수</strong>를 적용하여 각 단어의 중요도를 0~1 사이 값으로 변환합니다.</p><ul id="b61ae3fa-6184-4edb-a2a8-414f6c027c8f" class="bulleted-list"><li style="list-style-type:disc">예: &quot;I&quot;는 0.1, &quot;am&quot;은 0.2, &quot;a&quot;는 0.1, &quot;student&quot;는 0.6</li></ul><figure id="5943fc20-17ed-4f20-ac26-80d0e760661b" class="image"><a href="image%2070.png"><img style="width:567.984375px" src="image%2070.png"/></a></figure></li></ol><ol type="1" id="1fd4d778-1cdc-80e3-b12a-edbd174e242a" class="numbered-list" start="4"><li><strong>어텐션 값(Attention Value) 계산 (Weighted Sum)</strong><p id="86764850-8e36-4b44-a141-d16dd9f10739" class="">각 단어의 Value에 어텐션 가중치를 곱한 후 합산합니다.</p><ul id="3eebe2a8-bafa-41ac-be02-f7388e43d842" class="bulleted-list"><li style="list-style-type:disc">예: &quot;I&quot;의 Value × 0.1 + &quot;am&quot;의 Value × 0.2 + ...</li></ul><p id="96387bf5-e62c-4d54-9174-6af9acc904a8" class="">이렇게 계산된 값이 바로 컨텍스트 벡터(Context Vector)입니다.</p><p id="bd8dc59b-4df7-472b-b4af-7a1c76a16ce9" class="">컨텍스트 벡터는 디코더가 단어를 생성하는 데 필요한 정보를 담고 있습니다.</p><p id="1fd4d778-1cdc-8009-b82b-e15934653c70" class="">
</p><figure id="1fd4d778-1cdc-800c-86f1-e1f6404c92fd" class="image"><a href="image%2071.png"><img style="width:567.96875px" src="image%2071.png"/></a></figure></li></ol><ol type="1" id="1fd4d778-1cdc-80f8-b023-db4f98ab1ee8" class="numbered-list" start="5"><li><strong>출력 단어 생성</strong><p id="4afb04c0-c315-43d5-a6a7-5a878b219d78" class="">디코더는 컨텍스트 벡터와 이전의 은닉 상태를 결합(concatenate)하여 최종 출력 단어를 생성합니다.</p><figure id="2c084b8c-109f-44f1-a703-96f7dac339be" class="image"><a href="image%2072.png"><img style="width:567.984375px" src="image%2072.png"/></a></figure></li></ol><hr id="1fd4d778-1cdc-80f6-b17a-e4ce46357de6"/><p id="1fd4d778-1cdc-8021-9487-db3594b41df4" class=""><strong>Attention의 장점</strong></p><ol type="1" id="1fd4d778-1cdc-80fd-a39d-c64dcfe9f54b" class="numbered-list" start="1"><li><strong>긴 문장 처리 능력 향상</strong><br/>Seq2Seq가 긴 문장에서 정보를 요약하며 발생했던 정보 손실 문제를 해결합니다. 이제 디코더는 필요한 순간에 입력 문장의 특정 부분에 집중할 수 있습니다.<br/></li></ol><ol type="1" id="1fd4d778-1cdc-809a-b196-c3c248defbc6" class="numbered-list" start="2"><li><strong>출력 품질 향상</strong><br/>번역, 요약 등 다양한 작업에서 더 자연스럽고 정확한 결과를 제공합니다. 예를 들어, 한국어 문장 &quot;안녕하세요, 오늘 날씨가 좋네요&quot;를 영어로 번역할 때, &quot;날씨가 좋네요&quot; 부분에서 &quot;The weather is nice&quot;로 적절히 번역할 수 있습니다.<br/></li></ol><ol type="1" id="1fd4d778-1cdc-80cc-a69f-d7e4f71b7271" class="numbered-list" start="3"><li><strong>가시성 제공</strong><br/>Attention 메커니즘은 입력 문장에서 어느 부분에 주목했는지를 시각화할 수 있습니다. 이는 모델의 동작을 이해하고 개선하는 데 매우 유용합니다.<br/></li></ol><p id="1fd4d778-1cdc-80d3-a476-f5b850858f0b" class=""><strong>Attention의 한계</strong></p><p id="1fd4d778-1cdc-8012-a708-fc8331ba5a12" class="">Attention은 Seq2Seq의 문제를 크게 개선했지만, 모든 문제가 해결된 것은 아닙니다.</p><ol type="1" id="1fd4d778-1cdc-80f3-b40d-d6c8c6c07484" class="numbered-list" start="1"><li><strong>계산량 증가</strong><br/>입력 문장의 모든 단어에 대한 가중치를 계산하기 때문에, 문장이 길어질수록 계산 비용이 증가합니다.<br/></li></ol><ol type="1" id="1fd4d778-1cdc-8066-a7b8-da6f2e215d40" class="numbered-list" start="2"><li><strong>복잡성 증가</strong><br/>Attention은 추가적인 계산 단계를 필요로 하기 때문에 모델 구조가 복잡해질 수 있습니다.<br/></li></ol><hr id="1fd4d778-1cdc-802b-a64e-cb4ad48aad42"/><p id="1fd4d778-1cdc-8082-a43f-cc1c1e32b507" class=""><strong>Transformer로의 연결</strong></p><p id="1fd4d778-1cdc-8066-a30b-d704156b2074" class="">Attention은 Seq2Seq의 성능을 크게 개선했지만, 이를 더욱 발전시킨 모델이 등장했습니다. 바로 <strong>Transformer</strong>입니다. Transformer는 Attention 메커니즘을 기반으로 만들어졌으며, Seq2Seq와 RNN의 한계를 뛰어넘는 새로운 접근법을 제시했습니다. 다음 시간에는 Transformer가 Attention을 어떻게 활용하고, 무엇이 특별한지 알아보겠습니다.</p><p id="1fd4d778-1cdc-806a-a8f9-dbed6ac44e97" class="">
</p><h3 id="1fd4d778-1cdc-803b-96f0-c66959be617a" class="">요약</h3><p id="1fd4d778-1cdc-800d-b9ca-ec038d137130" class="">Attention은 Seq2Seq 모델의 한계를 극복하기 위해 도입된 메커니즘으로, 디코더가 출력 단어를 생성할 때 입력 문장에서 중요한 단어들에 집중할 수 있도록 도와줍니다. 이를 통해 긴 문장에서 정보 손실 문제를 줄이고 번역 품질을 향상시킵니다.</p><p id="1fd4d778-1cdc-80ab-9478-fc219eb39920" class="">
</p><ul id="1fd4d778-1cdc-8086-912a-e3d4e661ecd0" class="bulleted-list"><li style="list-style-type:disc"><strong>유사도 계산:</strong> 입력 문장의 각 단어와 디코더의 현재 상태 간의 유사도를 계산합니다.</li></ul><ul id="1fd4d778-1cdc-8072-82b7-efff702e49cc" class="bulleted-list"><li style="list-style-type:disc"><strong>중요도 반영:</strong> Softmax로 계산된 중요도를 통해 어떤 단어가 중요한지 나타냅니다.</li></ul><ul id="1fd4d778-1cdc-8056-b92b-c89a22b466b8" class="bulleted-list"><li style="list-style-type:disc"><strong>컨텍스트 벡터 생성:</strong> 중요한 단어 정보를 중심으로 컨텍스트 벡터를 만듭니다.</li></ul><ul id="1fd4d778-1cdc-80fa-a707-c839f13574da" class="bulleted-list"><li style="list-style-type:disc"><strong>출력 단어 생성:</strong> 이 벡터를 기반으로 디코더가 단어를 생성합니다.</li></ul><h3 id="1fd4d778-1cdc-803e-9211-d69d1ac537e3" class="">간단 퀴즈</h3><p id="1fd4d778-1cdc-804b-b870-e19cadd98466" class=""><strong>Q.1</strong></p><p id="1fd4d778-1cdc-8073-9366-ece80359fe66" class="">Attention 메커니즘의 주요 목적은 무엇인가요?</p><ol type="1" id="1fd4d778-1cdc-8077-8809-e6b8cdcb3d38" class="numbered-list" start="1"><li>입력 문장을 요약하여 하나의 벡터로 변환하는 것</li></ol><ol type="1" id="1fd4d778-1cdc-801c-a89a-ed60a81cc28e" class="numbered-list" start="2"><li>입력 문장에서 중요한 부분에 가중치를 부여하여 디코더가 참고할 수 있도록 하는 것</li></ol><ol type="1" id="1fd4d778-1cdc-804f-aa03-d273adc5d39d" class="numbered-list" start="3"><li>출력 문장의 길이를 입력 문장과 동일하게 만드는 것</li></ol><ul id="1fd4d778-1cdc-80fd-bf98-f3027563ad2d" class="toggle"><li><details open=""><summary><strong>정답</strong></summary><p id="ce02a503-46a6-4202-9b2f-c420c6c24bdd" class="">2</p></details></li></ul><hr id="1fd4d778-1cdc-8011-be4f-e0e7b5e7fbc3"/><p id="1fd4d778-1cdc-8087-9c54-d12b97aeb352" class=""><strong>Q.2</strong></p><p id="1fd4d778-1cdc-806c-b504-d4f367274755" class="">Attention을 사용하면 Seq2Seq 모델의 어떤 문제가 개선되나요?</p><ol type="1" id="1fd4d778-1cdc-80cd-bb2d-da610571eb2a" class="numbered-list" start="1"><li>고정된 출력 길이 문제</li></ol><ol type="1" id="1fd4d778-1cdc-8089-8bd8-f4c7b7e8e2b3" class="numbered-list" start="2"><li>긴 문장에서 정보 손실 문제</li></ol><ol type="1" id="1fd4d778-1cdc-806b-9078-e9de4cdeb1a5" class="numbered-list" start="3"><li>단어 선택 오류 문제</li></ol><ul id="1fd4d778-1cdc-8060-b08c-fc3a9e2b51e7" class="toggle"><li><details open=""><summary><strong>정답</strong></summary><p id="9ef631f0-f7ce-4c4a-b237-cc4246f54b08" class="">2</p></details></li></ul><hr id="1fd4d778-1cdc-80cd-8ce7-ee4d7754b6ca"/><p id="1fd4d778-1cdc-8001-980c-fe8e6016113d" class=""><strong>Q.3</strong></p><p id="1fd4d778-1cdc-8016-8172-ee3a4dfda877" class="">Attention 메커니즘의 작동 방식 중 <strong>가중치</strong>는 무엇을 나타내나요?</p><ol type="1" id="1fd4d778-1cdc-8057-b4ec-cb48caad1b14" class="numbered-list" start="1"><li>입력 문장의 각 단어가 현재 출력 단어와 얼마나 관련이 있는지</li></ol><ol type="1" id="1fd4d778-1cdc-8099-8b7e-d1fcec733e1d" class="numbered-list" start="2"><li>디코더가 출력할 단어의 길이</li></ol><ol type="1" id="1fd4d778-1cdc-804c-9de2-d4fc39041c46" class="numbered-list" start="3"><li>출력 문장이 생성된 순서</li></ol><ul id="1fd4d778-1cdc-8036-a9f4-e5a397845946" class="toggle"><li><details open=""><summary><strong>정답</strong></summary><p id="32284306-c278-4e97-8efa-564415fa0a83" class="">1</p></details></li></ul><p id="1fd4d778-1cdc-80dd-8cf8-cc2c5f2f88c6" class="">
</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>